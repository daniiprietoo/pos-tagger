{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04070e16",
   "metadata": {},
   "source": [
    "# Experiments of Different Model Arcitectures\n",
    "\n",
    "This notebook runs all experiments for the final report. It uses the modular code from the `.py` modules to:\n",
    "1.  Define multiple model configurations.\n",
    "2.  Train and evaluate each configuration on multiple languages (English, Spanish, German).\n",
    "3.  Collect and display dataset statistics (vocab size, tag count, etc.).\n",
    "4.  Collate all performance metrics into summary tables.\n",
    "5.  Run qualitative error analysis on a saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba5fea",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1258965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from data.preprocessor import DataPreprocessor, DataPreprocessorConfig\n",
    "from models.base_model import ModelConfig\n",
    "from models.lstm_model import LSTMModel\n",
    "from trainer.trainer import TrainerConfig, Trainer\n",
    "from evaluator.evaluator import Evaluator\n",
    "from inference.predictor import Predictor\n",
    "from utils import load_data\n",
    "\n",
    "keras.utils.set_random_seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c255d",
   "metadata": {},
   "source": [
    "## 2. Experiment Configuration\n",
    "\n",
    "This is the main control panel. We can define all the languages and model architectures we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2363034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = [\"english\", \"spanish\", \"german\"]\n",
    "\n",
    "preprocessor_config = DataPreprocessorConfig(\n",
    "    padding_type=\"post\",\n",
    "    truncation_type=\"post\",\n",
    "    remove_long_sentences=True,\n",
    "    max_sequence_length=100, # As per your config\n",
    ")\n",
    "\n",
    "base_training_config = TrainerConfig(\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    early_stopping_patience=3,\n",
    "    learning_rate=1e-3,\n",
    "    model_dir=\"saved_models_experiment\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "EXPERIMENT_CONFIGS = {\n",
    "    \"LSTM_Embed_80_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=64,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"LSTM_Stacked_Embed_80_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=64,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers = 2\n",
    "    ),\n",
    "    \"LSTM_Embed_80_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=128,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"LSTM_Stacked_Embed_80_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=128,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers = 2\n",
    "    ),\n",
    "    \"LSTM_Embed_128_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=64,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"LSTM_Stacked_Embed_128_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=64,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers = 2\n",
    "    ),\n",
    "    \"LSTM_Embed_128_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=128,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"LSTM_Stacked_Embed_128_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=128,\n",
    "        bidirectional=False,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers=2\n",
    "    ),\n",
    "    \"BiLSTM_Embed_80_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=64,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"BiLSTM_Stacked_Embed_80_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=64,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers=2\n",
    "    ),\n",
    "    \"BiLSTM_Embed_80_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=128,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"BiLSTM_Stacked_Embed_80_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=80,\n",
    "        lstm_units=128,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers=2\n",
    "    ),\n",
    "    \"BiLSTM_Embed_128_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=64,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"BiLSTM_Stacked_Embed_128_LSTM_64\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=64,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers=2\n",
    "    ),\n",
    "    \"BiLSTM_Embed_128_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=128,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config\n",
    "    ),\n",
    "    \"BiLSTM_Stacked_Embed_128_LSTM_128\": ModelConfig(\n",
    "        embedding_dim=128,\n",
    "        lstm_units=128,\n",
    "        bidirectional=True,\n",
    "        dropout_rate=0.3,\n",
    "        training_config=base_training_config,\n",
    "        lstm_layers=2\n",
    "    )\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "if not os.path.exists(base_training_config.model_dir):\n",
    "    os.makedirs(base_training_config.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b626ab",
   "metadata": {},
   "source": [
    "## 3. Main Experiment Loop\n",
    "\n",
    "This loop will iterate through every model configuration and train/evaluate it on every language. All results will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33122884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,612,435</span> (6.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,612,435\u001b[0m (6.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,612,435</span> (6.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,612,435\u001b[0m (6.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - _masked_accuracy: 0.3491 - loss: 2.2972\n",
      "Epoch 1: val_loss improved from None to 0.81489, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - _masked_accuracy: 0.5271 - loss: 1.6781 - val__masked_accuracy: 0.7709 - val_loss: 0.8149\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - _masked_accuracy: 0.8338 - loss: 0.6127\n",
      "Epoch 2: val_loss improved from 0.81489 to 0.47868, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - _masked_accuracy: 0.8650 - loss: 0.5033 - val__masked_accuracy: 0.8592 - val_loss: 0.4787\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - _masked_accuracy: 0.9144 - loss: 0.3143\n",
      "Epoch 3: val_loss improved from 0.47868 to 0.41239, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - _masked_accuracy: 0.9223 - loss: 0.2819 - val__masked_accuracy: 0.8742 - val_loss: 0.4124\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - _masked_accuracy: 0.9364 - loss: 0.2202\n",
      "Epoch 4: val_loss improved from 0.41239 to 0.39496, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - _masked_accuracy: 0.9404 - loss: 0.2045 - val__masked_accuracy: 0.8812 - val_loss: 0.3950\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9463 - loss: 0.1747\n",
      "Epoch 5: val_loss improved from 0.39496 to 0.39254, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - _masked_accuracy: 0.9486 - loss: 0.1660 - val__masked_accuracy: 0.8835 - val_loss: 0.3925\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - _masked_accuracy: 0.9521 - loss: 0.1498\n",
      "Epoch 6: val_loss did not improve from 0.39254\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - _masked_accuracy: 0.9537 - loss: 0.1438 - val__masked_accuracy: 0.8850 - val_loss: 0.3977\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - _masked_accuracy: 0.9567 - loss: 0.1321\n",
      "Epoch 7: val_loss did not improve from 0.39254\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - _masked_accuracy: 0.9582 - loss: 0.1278 - val__masked_accuracy: 0.8855 - val_loss: 0.4057\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - _masked_accuracy: 0.9604 - loss: 0.1203\n",
      "Epoch 8: val_loss did not improve from 0.39254\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - _masked_accuracy: 0.9613 - loss: 0.1164 - val__masked_accuracy: 0.8853 - val_loss: 0.4106\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8891\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.84      0.85      1788\n",
      "         ADP       0.89      0.93      0.91      2029\n",
      "         ADV       0.91      0.83      0.87      1191\n",
      "         AUX       0.94      0.96      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.97      0.97      0.97      1897\n",
      "        INTJ       0.99      0.69      0.81       121\n",
      "        NOUN       0.75      0.93      0.83      4123\n",
      "         NUM       0.90      0.68      0.77       542\n",
      "        PART       0.86      0.95      0.90       649\n",
      "        PRON       0.96      0.97      0.96      2165\n",
      "       PROPN       0.90      0.56      0.69      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.82      0.59      0.68       384\n",
      "         SYM       0.81      0.80      0.80       109\n",
      "        VERB       0.88      0.90      0.89      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.89     25096\n",
      "   macro avg       0.85      0.80      0.82     25096\n",
      "weighted avg       0.89      0.89      0.89     25096\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,729,075</span> (14.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,729,075\u001b[0m (14.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,729,075</span> (14.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,729,075\u001b[0m (14.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - _masked_accuracy: 0.4454 - loss: 2.0027\n",
      "Epoch 1: val_loss improved from None to 0.57353, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - _masked_accuracy: 0.6226 - loss: 1.3508 - val__masked_accuracy: 0.8426 - val_loss: 0.5735\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.8811 - loss: 0.4576\n",
      "Epoch 2: val_loss improved from 0.57353 to 0.28777, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9070 - loss: 0.3702 - val__masked_accuracy: 0.9213 - val_loss: 0.2878\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - _masked_accuracy: 0.9465 - loss: 0.2198\n",
      "Epoch 3: val_loss improved from 0.28777 to 0.24129, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9520 - loss: 0.1968 - val__masked_accuracy: 0.9298 - val_loss: 0.2413\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - _masked_accuracy: 0.9615 - loss: 0.1494\n",
      "Epoch 4: val_loss improved from 0.24129 to 0.22956, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9632 - loss: 0.1404 - val__masked_accuracy: 0.9302 - val_loss: 0.2296\n",
      "Epoch 5/20\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - _masked_accuracy: 0.9656 - loss: 0.1214\n",
      "Epoch 5: val_loss improved from 0.22956 to 0.22753, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - _masked_accuracy: 0.9669 - loss: 0.1160 - val__masked_accuracy: 0.9290 - val_loss: 0.2275\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - _masked_accuracy: 0.9685 - loss: 0.1056\n",
      "Epoch 6: val_loss did not improve from 0.22753\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - _masked_accuracy: 0.9691 - loss: 0.1021 - val__masked_accuracy: 0.9288 - val_loss: 0.2290\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - _masked_accuracy: 0.9703 - loss: 0.0957\n",
      "Epoch 7: val_loss did not improve from 0.22753\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - _masked_accuracy: 0.9708 - loss: 0.0930 - val__masked_accuracy: 0.9294 - val_loss: 0.2307\n",
      "Epoch 8/20\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.9719 - loss: 0.0886\n",
      "Epoch 8: val_loss did not improve from 0.22753\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9727 - loss: 0.0857 - val__masked_accuracy: 0.9286 - val_loss: 0.2358\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9253\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.85      0.85       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.90      0.94       424\n",
      "         AUX       0.85      0.96      0.90       331\n",
      "       CCONJ       0.98      0.90      0.94       395\n",
      "         DET       0.95      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.90      0.94      0.92      2225\n",
      "         NUM       0.98      0.75      0.85       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.89      0.83      0.86       445\n",
      "       PROPN       0.78      0.82      0.80       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.89      0.90      0.90       336\n",
      "         SYM       0.95      0.76      0.84        25\n",
      "        VERB       0.90      0.86      0.88      1167\n",
      "           X       0.32      0.13      0.18        46\n",
      "\n",
      "    accuracy                           0.93     11941\n",
      "   macro avg       0.78      0.74      0.75     11941\n",
      "weighted avg       0.92      0.93      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,998,435</span> (15.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,998,435\u001b[0m (15.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,998,435</span> (15.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,998,435\u001b[0m (15.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - _masked_accuracy: 0.3737 - loss: 2.1691\n",
      "Epoch 1: val_loss improved from None to 0.88630, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 58ms/step - _masked_accuracy: 0.5320 - loss: 1.5819 - val__masked_accuracy: 0.7460 - val_loss: 0.8863\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.8241 - loss: 0.6184\n",
      "Epoch 2: val_loss improved from 0.88630 to 0.42675, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.8655 - loss: 0.4899 - val__masked_accuracy: 0.8791 - val_loss: 0.4268\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.9377 - loss: 0.2557\n",
      "Epoch 3: val_loss improved from 0.42675 to 0.34050, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9474 - loss: 0.2191 - val__masked_accuracy: 0.8987 - val_loss: 0.3405\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.9632 - loss: 0.1480\n",
      "Epoch 4: val_loss improved from 0.34050 to 0.32739, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - _masked_accuracy: 0.9660 - loss: 0.1354 - val__masked_accuracy: 0.9013 - val_loss: 0.3274\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.9706 - loss: 0.1085\n",
      "Epoch 5: val_loss improved from 0.32739 to 0.32412, saving model to saved_models_experiment/LSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - _masked_accuracy: 0.9718 - loss: 0.1032 - val__masked_accuracy: 0.9016 - val_loss: 0.3241\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - _masked_accuracy: 0.9749 - loss: 0.0881\n",
      "Epoch 6: val_loss did not improve from 0.32412\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - _masked_accuracy: 0.9758 - loss: 0.0850 - val__masked_accuracy: 0.9010 - val_loss: 0.3351\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - _masked_accuracy: 0.9781 - loss: 0.0750\n",
      "Epoch 7: val_loss did not improve from 0.32412\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 66ms/step - _masked_accuracy: 0.9788 - loss: 0.0727 - val__masked_accuracy: 0.8980 - val_loss: 0.3434\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - _masked_accuracy: 0.9810 - loss: 0.0644\n",
      "Epoch 8: val_loss did not improve from 0.32412\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - _masked_accuracy: 0.9815 - loss: 0.0632 - val__masked_accuracy: 0.8959 - val_loss: 0.3647\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8971\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.67      0.78      1249\n",
      "         ADP       0.94      0.98      0.96      1603\n",
      "         ADV       0.93      0.90      0.92      1058\n",
      "         AUX       0.88      0.97      0.92       691\n",
      "       CCONJ       0.98      0.93      0.95       460\n",
      "         DET       0.97      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.86      0.89      0.87      3111\n",
      "         NUM       0.94      0.88      0.91       233\n",
      "        PART       0.91      0.76      0.83       210\n",
      "        PRON       0.95      0.91      0.93       705\n",
      "       PROPN       0.57      0.87      0.69      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.89      0.73      0.80       168\n",
      "         SYM       1.00      0.25      0.40         4\n",
      "        VERB       0.93      0.74      0.82      1326\n",
      "           X       1.00      0.04      0.08        25\n",
      "\n",
      "    accuracy                           0.90     16499\n",
      "   macro avg       0.86      0.74      0.76     16499\n",
      "weighted avg       0.91      0.90      0.90     16499\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,243</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,243\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,243</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,243\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - _masked_accuracy: 0.1815 - loss: 2.6111\n",
      "Epoch 1: val_loss improved from None to 1.57344, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 63ms/step - _masked_accuracy: 0.2843 - loss: 2.2874 - val__masked_accuracy: 0.5074 - val_loss: 1.5734\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - _masked_accuracy: 0.5702 - loss: 1.3707\n",
      "Epoch 2: val_loss improved from 1.57344 to 0.89754, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - _masked_accuracy: 0.6473 - loss: 1.1937 - val__masked_accuracy: 0.7697 - val_loss: 0.8975\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - _masked_accuracy: 0.7962 - loss: 0.7648\n",
      "Epoch 3: val_loss improved from 0.89754 to 0.62016, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.8211 - loss: 0.6775 - val__masked_accuracy: 0.8356 - val_loss: 0.6202\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - _masked_accuracy: 0.8735 - loss: 0.5035\n",
      "Epoch 4: val_loss improved from 0.62016 to 0.51517, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - _masked_accuracy: 0.8826 - loss: 0.4639 - val__masked_accuracy: 0.8530 - val_loss: 0.5152\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9029 - loss: 0.3816\n",
      "Epoch 5: val_loss improved from 0.51517 to 0.45961, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.9089 - loss: 0.3553 - val__masked_accuracy: 0.8633 - val_loss: 0.4596\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9190 - loss: 0.3064\n",
      "Epoch 6: val_loss improved from 0.45961 to 0.44441, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - _masked_accuracy: 0.9218 - loss: 0.2910 - val__masked_accuracy: 0.8632 - val_loss: 0.4444\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - _masked_accuracy: 0.9264 - loss: 0.2659\n",
      "Epoch 7: val_loss improved from 0.44441 to 0.42551, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.9294 - loss: 0.2540 - val__masked_accuracy: 0.8704 - val_loss: 0.4255\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - _masked_accuracy: 0.9331 - loss: 0.2369\n",
      "Epoch 8: val_loss did not improve from 0.42551\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.9351 - loss: 0.2283 - val__masked_accuracy: 0.8726 - val_loss: 0.4295\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9373 - loss: 0.2175\n",
      "Epoch 9: val_loss improved from 0.42551 to 0.41859, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - _masked_accuracy: 0.9393 - loss: 0.2094 - val__masked_accuracy: 0.8774 - val_loss: 0.4186\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9426 - loss: 0.1994\n",
      "Epoch 10: val_loss did not improve from 0.41859\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.9439 - loss: 0.1938 - val__masked_accuracy: 0.8762 - val_loss: 0.4267\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9445 - loss: 0.1872\n",
      "Epoch 11: val_loss did not improve from 0.41859\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - _masked_accuracy: 0.9465 - loss: 0.1808 - val__masked_accuracy: 0.8753 - val_loss: 0.4295\n",
      "Epoch 12/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - _masked_accuracy: 0.9477 - loss: 0.1764\n",
      "Epoch 12: val_loss did not improve from 0.41859\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - _masked_accuracy: 0.9487 - loss: 0.1713 - val__masked_accuracy: 0.8778 - val_loss: 0.4260\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8792\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.71      0.86      0.78      1788\n",
      "         ADP       0.88      0.92      0.90      2029\n",
      "         ADV       0.90      0.84      0.87      1191\n",
      "         AUX       0.94      0.94      0.94      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.96      0.97      0.96      1897\n",
      "        INTJ       0.91      0.61      0.73       121\n",
      "        NOUN       0.77      0.91      0.83      4123\n",
      "         NUM       0.91      0.61      0.73       542\n",
      "        PART       0.82      0.94      0.87       649\n",
      "        PRON       0.96      0.96      0.96      2165\n",
      "       PROPN       0.87      0.57      0.69      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.78      0.58      0.67       384\n",
      "         SYM       0.82      0.77      0.80       109\n",
      "        VERB       0.92      0.87      0.89      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.88     25096\n",
      "   macro avg       0.83      0.78      0.80     25096\n",
      "weighted avg       0.88      0.88      0.88     25096\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,740,883</span> (14.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,740,883\u001b[0m (14.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,740,883</span> (14.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,740,883\u001b[0m (14.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - _masked_accuracy: 0.2694 - loss: 2.3278\n",
      "Epoch 1: val_loss improved from None to 1.06703, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - _masked_accuracy: 0.4188 - loss: 1.8440 - val__masked_accuracy: 0.6510 - val_loss: 1.0670\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.7016 - loss: 0.9438\n",
      "Epoch 2: val_loss improved from 1.06703 to 0.57520, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.7562 - loss: 0.8124 - val__masked_accuracy: 0.8589 - val_loss: 0.5752\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.8734 - loss: 0.5221\n",
      "Epoch 3: val_loss improved from 0.57520 to 0.38241, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 74ms/step - _masked_accuracy: 0.8916 - loss: 0.4624 - val__masked_accuracy: 0.9049 - val_loss: 0.3824\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - _masked_accuracy: 0.9294 - loss: 0.3219\n",
      "Epoch 4: val_loss improved from 0.38241 to 0.30583, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 74ms/step - _masked_accuracy: 0.9374 - loss: 0.2900 - val__masked_accuracy: 0.9202 - val_loss: 0.3058\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9517 - loss: 0.2217\n",
      "Epoch 5: val_loss improved from 0.30583 to 0.27258, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.9543 - loss: 0.2081 - val__masked_accuracy: 0.9281 - val_loss: 0.2726\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - _masked_accuracy: 0.9583 - loss: 0.1786\n",
      "Epoch 6: val_loss improved from 0.27258 to 0.26187, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - _masked_accuracy: 0.9593 - loss: 0.1723 - val__masked_accuracy: 0.9287 - val_loss: 0.2619\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9607 - loss: 0.1574\n",
      "Epoch 7: val_loss improved from 0.26187 to 0.26137, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.9611 - loss: 0.1540 - val__masked_accuracy: 0.9279 - val_loss: 0.2614\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9631 - loss: 0.1444\n",
      "Epoch 8: val_loss improved from 0.26137 to 0.25847, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.9636 - loss: 0.1418 - val__masked_accuracy: 0.9290 - val_loss: 0.2585\n",
      "Epoch 9/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9645 - loss: 0.1354\n",
      "Epoch 9: val_loss did not improve from 0.25847\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.9650 - loss: 0.1334 - val__masked_accuracy: 0.9288 - val_loss: 0.2609\n",
      "Epoch 10/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9661 - loss: 0.1271\n",
      "Epoch 10: val_loss did not improve from 0.25847\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9667 - loss: 0.1249 - val__masked_accuracy: 0.9291 - val_loss: 0.2625\n",
      "Epoch 11/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - _masked_accuracy: 0.9673 - loss: 0.1212\n",
      "Epoch 11: val_loss did not improve from 0.25847\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 75ms/step - _masked_accuracy: 0.9677 - loss: 0.1191 - val__masked_accuracy: 0.9299 - val_loss: 0.2650\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9223\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.82      0.86      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.99      0.89      0.94       424\n",
      "         AUX       0.85      0.96      0.90       331\n",
      "       CCONJ       0.99      0.88      0.93       395\n",
      "         DET       0.96      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.93      0.91      0.92      2225\n",
      "         NUM       0.95      0.75      0.84       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.91      0.82      0.86       445\n",
      "       PROPN       0.69      0.90      0.78       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.87      0.95      0.91       336\n",
      "         SYM       0.88      0.84      0.86        25\n",
      "        VERB       0.96      0.82      0.88      1167\n",
      "           X       0.27      0.09      0.13        46\n",
      "\n",
      "    accuracy                           0.92     11941\n",
      "   macro avg       0.77      0.74      0.75     11941\n",
      "weighted avg       0.93      0.92      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,010,243</span> (15.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,010,243\u001b[0m (15.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,010,243</span> (15.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,010,243\u001b[0m (15.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - _masked_accuracy: 0.2413 - loss: 2.4656\n",
      "Epoch 1: val_loss improved from None to 1.50101, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - _masked_accuracy: 0.3604 - loss: 2.0818 - val__masked_accuracy: 0.5048 - val_loss: 1.5010\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - _masked_accuracy: 0.6387 - loss: 1.1440\n",
      "Epoch 2: val_loss improved from 1.50101 to 0.79263, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.7143 - loss: 0.9684 - val__masked_accuracy: 0.8172 - val_loss: 0.7926\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - _masked_accuracy: 0.8739 - loss: 0.5453\n",
      "Epoch 3: val_loss improved from 0.79263 to 0.55445, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.8933 - loss: 0.4634 - val__masked_accuracy: 0.8603 - val_loss: 0.5545\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - _masked_accuracy: 0.9313 - loss: 0.3081\n",
      "Epoch 4: val_loss improved from 0.55445 to 0.49552, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - _masked_accuracy: 0.9388 - loss: 0.2795 - val__masked_accuracy: 0.8684 - val_loss: 0.4955\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9531 - loss: 0.2206\n",
      "Epoch 5: val_loss did not improve from 0.49552\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9564 - loss: 0.2051 - val__masked_accuracy: 0.8736 - val_loss: 0.4967\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9609 - loss: 0.1774\n",
      "Epoch 6: val_loss improved from 0.49552 to 0.49186, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9627 - loss: 0.1683 - val__masked_accuracy: 0.8753 - val_loss: 0.4919\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - _masked_accuracy: 0.9648 - loss: 0.1527\n",
      "Epoch 7: val_loss did not improve from 0.49186\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - _masked_accuracy: 0.9656 - loss: 0.1471 - val__masked_accuracy: 0.8751 - val_loss: 0.4930\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - _masked_accuracy: 0.9672 - loss: 0.1373\n",
      "Epoch 8: val_loss improved from 0.49186 to 0.48262, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9677 - loss: 0.1331 - val__masked_accuracy: 0.8822 - val_loss: 0.4826\n",
      "Epoch 9/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9684 - loss: 0.1264\n",
      "Epoch 9: val_loss did not improve from 0.48262\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9693 - loss: 0.1225 - val__masked_accuracy: 0.8837 - val_loss: 0.4905\n",
      "Epoch 10/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9696 - loss: 0.1182\n",
      "Epoch 10: val_loss did not improve from 0.48262\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9704 - loss: 0.1145 - val__masked_accuracy: 0.8819 - val_loss: 0.5111\n",
      "Epoch 11/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - _masked_accuracy: 0.9715 - loss: 0.1097\n",
      "Epoch 11: val_loss did not improve from 0.48262\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.9723 - loss: 0.1065 - val__masked_accuracy: 0.8837 - val_loss: 0.4912\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8719\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.93      0.67      0.78      1249\n",
      "         ADP       0.93      0.99      0.96      1603\n",
      "         ADV       0.93      0.89      0.91      1058\n",
      "         AUX       0.87      0.96      0.92       691\n",
      "       CCONJ       0.99      0.93      0.96       460\n",
      "         DET       0.96      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.93      0.77      0.84      3111\n",
      "         NUM       0.97      0.89      0.93       233\n",
      "        PART       0.99      0.63      0.77       210\n",
      "        PRON       0.95      0.91      0.93       705\n",
      "       PROPN       0.41      0.93      0.57      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.89      0.74      0.81       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.94      0.70      0.80      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.87     16499\n",
      "   macro avg       0.75      0.70      0.71     16499\n",
      "weighted avg       0.91      0.87      0.88     16499\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,683,539</span> (6.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,683,539\u001b[0m (6.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,683,539</span> (6.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,683,539\u001b[0m (6.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.3478 - loss: 2.2197\n",
      "Epoch 1: val_loss improved from None to 0.73381, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 109ms/step - _masked_accuracy: 0.5402 - loss: 1.5712 - val__masked_accuracy: 0.7858 - val_loss: 0.7338\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - _masked_accuracy: 0.8443 - loss: 0.5433\n",
      "Epoch 2: val_loss improved from 0.73381 to 0.44168, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 106ms/step - _masked_accuracy: 0.8737 - loss: 0.4468 - val__masked_accuracy: 0.8698 - val_loss: 0.4417\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9211 - loss: 0.2814\n",
      "Epoch 3: val_loss improved from 0.44168 to 0.39332, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - _masked_accuracy: 0.9286 - loss: 0.2526 - val__masked_accuracy: 0.8811 - val_loss: 0.3933\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9418 - loss: 0.1969\n",
      "Epoch 4: val_loss improved from 0.39332 to 0.38309, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - _masked_accuracy: 0.9453 - loss: 0.1830 - val__masked_accuracy: 0.8845 - val_loss: 0.3831\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9514 - loss: 0.1570\n",
      "Epoch 5: val_loss improved from 0.38309 to 0.38258, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - _masked_accuracy: 0.9532 - loss: 0.1487 - val__masked_accuracy: 0.8869 - val_loss: 0.3826\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - _masked_accuracy: 0.9566 - loss: 0.1341\n",
      "Epoch 6: val_loss did not improve from 0.38258\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - _masked_accuracy: 0.9582 - loss: 0.1284 - val__masked_accuracy: 0.8859 - val_loss: 0.3936\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - _masked_accuracy: 0.9599 - loss: 0.1195\n",
      "Epoch 7: val_loss did not improve from 0.38258\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 112ms/step - _masked_accuracy: 0.9616 - loss: 0.1145 - val__masked_accuracy: 0.8850 - val_loss: 0.4030\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - _masked_accuracy: 0.9645 - loss: 0.1066\n",
      "Epoch 8: val_loss did not improve from 0.38258\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - _masked_accuracy: 0.9653 - loss: 0.1032 - val__masked_accuracy: 0.8851 - val_loss: 0.4093\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8896\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.85      0.84      0.84      1788\n",
      "         ADP       0.90      0.92      0.91      2029\n",
      "         ADV       0.88      0.85      0.87      1191\n",
      "         AUX       0.94      0.95      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.97      0.97      0.97      1897\n",
      "        INTJ       0.96      0.68      0.80       121\n",
      "        NOUN       0.75      0.94      0.84      4123\n",
      "         NUM       0.93      0.65      0.77       542\n",
      "        PART       0.86      0.95      0.90       649\n",
      "        PRON       0.97      0.96      0.96      2165\n",
      "       PROPN       0.89      0.57      0.70      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.76      0.63      0.69       384\n",
      "         SYM       0.79      0.84      0.82       109\n",
      "        VERB       0.90      0.90      0.90      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.89     25096\n",
      "   macro avg       0.84      0.80      0.82     25096\n",
      "weighted avg       0.89      0.89      0.89     25096\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,800,179</span> (14.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,800,179\u001b[0m (14.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,800,179</span> (14.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,800,179\u001b[0m (14.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - _masked_accuracy: 0.4661 - loss: 1.8720\n",
      "Epoch 1: val_loss improved from None to 0.48106, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 106ms/step - _masked_accuracy: 0.6452 - loss: 1.2238 - val__masked_accuracy: 0.8588 - val_loss: 0.4811\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - _masked_accuracy: 0.8908 - loss: 0.3928\n",
      "Epoch 2: val_loss improved from 0.48106 to 0.26237, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 105ms/step - _masked_accuracy: 0.9123 - loss: 0.3231 - val__masked_accuracy: 0.9254 - val_loss: 0.2624\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9481 - loss: 0.1991\n",
      "Epoch 3: val_loss improved from 0.26237 to 0.22737, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - _masked_accuracy: 0.9535 - loss: 0.1783 - val__masked_accuracy: 0.9317 - val_loss: 0.2274\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - _masked_accuracy: 0.9626 - loss: 0.1380\n",
      "Epoch 4: val_loss improved from 0.22737 to 0.21960, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - _masked_accuracy: 0.9646 - loss: 0.1293 - val__masked_accuracy: 0.9319 - val_loss: 0.2196\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - _masked_accuracy: 0.9673 - loss: 0.1128\n",
      "Epoch 5: val_loss did not improve from 0.21960\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - _masked_accuracy: 0.9684 - loss: 0.1071 - val__masked_accuracy: 0.9311 - val_loss: 0.2203\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - _masked_accuracy: 0.9701 - loss: 0.0979\n",
      "Epoch 6: val_loss did not improve from 0.21960\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - _masked_accuracy: 0.9709 - loss: 0.0940 - val__masked_accuracy: 0.9308 - val_loss: 0.2237\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - _masked_accuracy: 0.9722 - loss: 0.0878\n",
      "Epoch 7: val_loss did not improve from 0.21960\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 136ms/step - _masked_accuracy: 0.9730 - loss: 0.0845 - val__masked_accuracy: 0.9299 - val_loss: 0.2311\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9254\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.85      0.85       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.96      0.90      0.93       424\n",
      "         AUX       0.86      0.95      0.90       331\n",
      "       CCONJ       0.98      0.90      0.94       395\n",
      "         DET       0.96      0.98      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.91      0.93      0.92      2225\n",
      "         NUM       0.99      0.77      0.86       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.89      0.82      0.86       445\n",
      "       PROPN       0.75      0.83      0.79       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.89      0.91      0.90       336\n",
      "         SYM       1.00      0.76      0.86        25\n",
      "        VERB       0.91      0.87      0.89      1167\n",
      "           X       0.31      0.09      0.14        46\n",
      "\n",
      "    accuracy                           0.93     11941\n",
      "   macro avg       0.78      0.74      0.75     11941\n",
      "weighted avg       0.93      0.93      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_80_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,069,539</span> (15.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,069,539\u001b[0m (15.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,069,539</span> (15.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,069,539\u001b[0m (15.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - _masked_accuracy: 0.3863 - loss: 2.0720\n",
      "Epoch 1: val_loss improved from None to 0.75015, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 106ms/step - _masked_accuracy: 0.5532 - loss: 1.4577 - val__masked_accuracy: 0.7867 - val_loss: 0.7501\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.8431 - loss: 0.5319\n",
      "Epoch 2: val_loss improved from 0.75015 to 0.40686, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 105ms/step - _masked_accuracy: 0.8777 - loss: 0.4263 - val__masked_accuracy: 0.8807 - val_loss: 0.4069\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9402 - loss: 0.2323\n",
      "Epoch 3: val_loss improved from 0.40686 to 0.35318, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 104ms/step - _masked_accuracy: 0.9499 - loss: 0.1993 - val__masked_accuracy: 0.8904 - val_loss: 0.3532\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - _masked_accuracy: 0.9639 - loss: 0.1387\n",
      "Epoch 4: val_loss improved from 0.35318 to 0.31697, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 105ms/step - _masked_accuracy: 0.9664 - loss: 0.1272 - val__masked_accuracy: 0.9013 - val_loss: 0.3170\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - _masked_accuracy: 0.9710 - loss: 0.1013\n",
      "Epoch 5: val_loss improved from 0.31697 to 0.30960, saving model to saved_models_experiment/LSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 108ms/step - _masked_accuracy: 0.9726 - loss: 0.0958 - val__masked_accuracy: 0.9043 - val_loss: 0.3096\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - _masked_accuracy: 0.9759 - loss: 0.0804\n",
      "Epoch 6: val_loss did not improve from 0.30960\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 113ms/step - _masked_accuracy: 0.9772 - loss: 0.0768 - val__masked_accuracy: 0.9035 - val_loss: 0.3176\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - _masked_accuracy: 0.9801 - loss: 0.0655\n",
      "Epoch 7: val_loss did not improve from 0.30960\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 126ms/step - _masked_accuracy: 0.9807 - loss: 0.0638 - val__masked_accuracy: 0.9030 - val_loss: 0.3253\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - _masked_accuracy: 0.9832 - loss: 0.0556\n",
      "Epoch 8: val_loss did not improve from 0.30960\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 132ms/step - _masked_accuracy: 0.9835 - loss: 0.0546 - val__masked_accuracy: 0.8907 - val_loss: 0.3770\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8946\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.77      0.73      0.75      1249\n",
      "         ADP       0.96      0.97      0.96      1603\n",
      "         ADV       0.93      0.90      0.92      1058\n",
      "         AUX       0.88      0.94      0.91       691\n",
      "       CCONJ       0.98      0.93      0.95       460\n",
      "         DET       0.97      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.89      0.87      0.88      3111\n",
      "         NUM       0.96      0.88      0.91       233\n",
      "        PART       0.84      0.87      0.85       210\n",
      "        PRON       0.94      0.92      0.93       705\n",
      "       PROPN       0.65      0.78      0.71      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.91      0.74      0.81       168\n",
      "         SYM       1.00      0.25      0.40         4\n",
      "        VERB       0.79      0.79      0.79      1326\n",
      "           X       0.17      0.04      0.06        25\n",
      "\n",
      "    accuracy                           0.89     16499\n",
      "   macro avg       0.80      0.74      0.75     16499\n",
      "weighted avg       0.90      0.89      0.89     16499\n",
      "\n",
      "--- Experiment for LSTM_Embed_80_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_18             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_18             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,731,731</span> (6.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,731,731\u001b[0m (6.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,731,731</span> (6.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,731,731\u001b[0m (6.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - _masked_accuracy: 0.2349 - loss: 2.4681\n",
      "Epoch 1: val_loss improved from None to 1.00626, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 153ms/step - _masked_accuracy: 0.3942 - loss: 1.9551 - val__masked_accuracy: 0.6933 - val_loss: 1.0063\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - _masked_accuracy: 0.7696 - loss: 0.7879\n",
      "Epoch 2: val_loss improved from 1.00626 to 0.57706, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 158ms/step - _masked_accuracy: 0.8122 - loss: 0.6570 - val__masked_accuracy: 0.8386 - val_loss: 0.5771\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - _masked_accuracy: 0.8835 - loss: 0.4307\n",
      "Epoch 3: val_loss improved from 0.57706 to 0.47898, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 161ms/step - _masked_accuracy: 0.8945 - loss: 0.3889 - val__masked_accuracy: 0.8558 - val_loss: 0.4790\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - _masked_accuracy: 0.9134 - loss: 0.3094\n",
      "Epoch 4: val_loss improved from 0.47898 to 0.44680, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1040s\u001b[0m 5s/step - _masked_accuracy: 0.9197 - loss: 0.2873 - val__masked_accuracy: 0.8599 - val_loss: 0.4468\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - _masked_accuracy: 0.9293 - loss: 0.2474 \n",
      "Epoch 5: val_loss improved from 0.44680 to 0.42091, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5826s\u001b[0m 30s/step - _masked_accuracy: 0.9334 - loss: 0.2333 - val__masked_accuracy: 0.8668 - val_loss: 0.4209\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - _masked_accuracy: 0.9370 - loss: 0.2118 \n",
      "Epoch 6: val_loss improved from 0.42091 to 0.41661, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9467s\u001b[0m 49s/step - _masked_accuracy: 0.9400 - loss: 0.2017 - val__masked_accuracy: 0.8710 - val_loss: 0.4166\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24s/step - _masked_accuracy: 0.9433 - loss: 0.1869 \n",
      "Epoch 7: val_loss improved from 0.41661 to 0.41416, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4730s\u001b[0m 24s/step - _masked_accuracy: 0.9455 - loss: 0.1802 - val__masked_accuracy: 0.8751 - val_loss: 0.4142\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - _masked_accuracy: 0.9472 - loss: 0.1711 \n",
      "Epoch 8: val_loss improved from 0.41416 to 0.41257, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4945s\u001b[0m 25s/step - _masked_accuracy: 0.9487 - loss: 0.1667 - val__masked_accuracy: 0.8766 - val_loss: 0.4126\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - _masked_accuracy: 0.9501 - loss: 0.1592 \n",
      "Epoch 9: val_loss did not improve from 0.41257\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2741s\u001b[0m 14s/step - _masked_accuracy: 0.9514 - loss: 0.1554 - val__masked_accuracy: 0.8771 - val_loss: 0.4155\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - _masked_accuracy: 0.9523 - loss: 0.1497\n",
      "Epoch 10: val_loss did not improve from 0.41257\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 150ms/step - _masked_accuracy: 0.9539 - loss: 0.1459 - val__masked_accuracy: 0.8771 - val_loss: 0.4204\n",
      "Epoch 11/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - _masked_accuracy: 0.9551 - loss: 0.1411\n",
      "Epoch 11: val_loss did not improve from 0.41257\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 156ms/step - _masked_accuracy: 0.9563 - loss: 0.1384 - val__masked_accuracy: 0.8804 - val_loss: 0.4145\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8779\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.57      0.89      0.70      1788\n",
      "         ADP       0.88      0.92      0.90      2029\n",
      "         ADV       0.91      0.85      0.88      1191\n",
      "         AUX       0.95      0.94      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.96      0.97      0.97      1897\n",
      "        INTJ       0.93      0.69      0.80       121\n",
      "        NOUN       0.88      0.85      0.86      4123\n",
      "         NUM       0.92      0.61      0.73       542\n",
      "        PART       0.84      0.96      0.89       649\n",
      "        PRON       0.97      0.95      0.96      2165\n",
      "       PROPN       0.83      0.60      0.70      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.77      0.59      0.67       384\n",
      "         SYM       0.75      0.82      0.78       109\n",
      "        VERB       0.91      0.88      0.90      2606\n",
      "           X       0.06      0.12      0.08        42\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88     25096\n",
      "   macro avg       0.79      0.76      0.76     25096\n",
      "weighted avg       0.89      0.88      0.88     25096\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_20             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_28 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_29 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_20             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,848,371</span> (14.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,848,371\u001b[0m (14.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,848,371</span> (14.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,848,371\u001b[0m (14.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - _masked_accuracy: 0.3184 - loss: 2.1841\n",
      "Epoch 1: val_loss improved from None to 0.82637, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - _masked_accuracy: 0.4899 - loss: 1.6293 - val__masked_accuracy: 0.7426 - val_loss: 0.8264\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - _masked_accuracy: 0.7957 - loss: 0.6871\n",
      "Epoch 2: val_loss improved from 0.82637 to 0.38370, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 170ms/step - _masked_accuracy: 0.8440 - loss: 0.5588 - val__masked_accuracy: 0.8956 - val_loss: 0.3837\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - _masked_accuracy: 0.9208 - loss: 0.3221\n",
      "Epoch 3: val_loss improved from 0.38370 to 0.31545, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 164ms/step - _masked_accuracy: 0.9302 - loss: 0.2849 - val__masked_accuracy: 0.9165 - val_loss: 0.3155\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - _masked_accuracy: 0.9473 - loss: 0.2134\n",
      "Epoch 4: val_loss improved from 0.31545 to 0.29276, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 164ms/step - _masked_accuracy: 0.9509 - loss: 0.1985 - val__masked_accuracy: 0.9199 - val_loss: 0.2928\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - _masked_accuracy: 0.9565 - loss: 0.1700\n",
      "Epoch 5: val_loss improved from 0.29276 to 0.28598, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 166ms/step - _masked_accuracy: 0.9579 - loss: 0.1631 - val__masked_accuracy: 0.9231 - val_loss: 0.2860\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - _masked_accuracy: 0.9606 - loss: 0.1480\n",
      "Epoch 6: val_loss improved from 0.28598 to 0.28115, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 164ms/step - _masked_accuracy: 0.9615 - loss: 0.1434 - val__masked_accuracy: 0.9238 - val_loss: 0.2812\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - _masked_accuracy: 0.9629 - loss: 0.1338\n",
      "Epoch 7: val_loss improved from 0.28115 to 0.28031, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 165ms/step - _masked_accuracy: 0.9639 - loss: 0.1306 - val__masked_accuracy: 0.9249 - val_loss: 0.2803\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - _masked_accuracy: 0.9654 - loss: 0.1235\n",
      "Epoch 8: val_loss did not improve from 0.28031\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 167ms/step - _masked_accuracy: 0.9659 - loss: 0.1212 - val__masked_accuracy: 0.9254 - val_loss: 0.2814\n",
      "Epoch 9/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - _masked_accuracy: 0.9668 - loss: 0.1159\n",
      "Epoch 9: val_loss did not improve from 0.28031\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 165ms/step - _masked_accuracy: 0.9674 - loss: 0.1138 - val__masked_accuracy: 0.9260 - val_loss: 0.2836\n",
      "Epoch 10/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - _masked_accuracy: 0.9686 - loss: 0.1092\n",
      "Epoch 10: val_loss did not improve from 0.28031\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 165ms/step - _masked_accuracy: 0.9691 - loss: 0.1067 - val__masked_accuracy: 0.9261 - val_loss: 0.2872\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9155\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.83      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.89      0.93       424\n",
      "         AUX       0.84      0.97      0.90       331\n",
      "       CCONJ       0.99      0.89      0.93       395\n",
      "         DET       0.96      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.97      0.87      0.91      2225\n",
      "         NUM       0.97      0.75      0.85       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.90      0.82      0.86       445\n",
      "       PROPN       0.60      0.96      0.74       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.87      0.91      0.89       336\n",
      "         SYM       0.91      0.80      0.85        25\n",
      "        VERB       0.96      0.81      0.88      1167\n",
      "           X       0.43      0.20      0.27        46\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92     11941\n",
      "   macro avg       0.73      0.70      0.71     11941\n",
      "weighted avg       0.93      0.92      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_80_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_22             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_22 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m107,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_22             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,117,731</span> (15.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,117,731\u001b[0m (15.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,117,731</span> (15.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,117,731\u001b[0m (15.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - _masked_accuracy: 0.2701 - loss: 2.3178\n",
      "Epoch 1: val_loss improved from None to 1.24191, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 161ms/step - _masked_accuracy: 0.4043 - loss: 1.8625 - val__masked_accuracy: 0.5681 - val_loss: 1.2419\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - _masked_accuracy: 0.7129 - loss: 0.8925\n",
      "Epoch 2: val_loss improved from 1.24191 to 0.56488, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - _masked_accuracy: 0.7806 - loss: 0.7148 - val__masked_accuracy: 0.8474 - val_loss: 0.5649\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - _masked_accuracy: 0.8989 - loss: 0.3887\n",
      "Epoch 3: val_loss improved from 0.56488 to 0.48272, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - _masked_accuracy: 0.9165 - loss: 0.3314 - val__masked_accuracy: 0.8601 - val_loss: 0.4827\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - _masked_accuracy: 0.9450 - loss: 0.2251\n",
      "Epoch 4: val_loss improved from 0.48272 to 0.47623, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - _masked_accuracy: 0.9498 - loss: 0.2050 - val__masked_accuracy: 0.8651 - val_loss: 0.4762\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - _masked_accuracy: 0.9590 - loss: 0.1651\n",
      "Epoch 5: val_loss did not improve from 0.47623\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 173ms/step - _masked_accuracy: 0.9608 - loss: 0.1559 - val__masked_accuracy: 0.8667 - val_loss: 0.4765\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - _masked_accuracy: 0.9643 - loss: 0.1362\n",
      "Epoch 6: val_loss improved from 0.47623 to 0.47152, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 174ms/step - _masked_accuracy: 0.9656 - loss: 0.1307 - val__masked_accuracy: 0.8711 - val_loss: 0.4715\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - _masked_accuracy: 0.9686 - loss: 0.1184\n",
      "Epoch 7: val_loss did not improve from 0.47152\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 167ms/step - _masked_accuracy: 0.9693 - loss: 0.1143 - val__masked_accuracy: 0.8767 - val_loss: 0.4804\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - _masked_accuracy: 0.9710 - loss: 0.1064\n",
      "Epoch 8: val_loss did not improve from 0.47152\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - _masked_accuracy: 0.9717 - loss: 0.1027 - val__masked_accuracy: 0.8775 - val_loss: 0.4809\n",
      "Epoch 9/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - _masked_accuracy: 0.9733 - loss: 0.0957\n",
      "Epoch 9: val_loss improved from 0.47152 to 0.46549, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 167ms/step - _masked_accuracy: 0.9739 - loss: 0.0934 - val__masked_accuracy: 0.8819 - val_loss: 0.4655\n",
      "Epoch 10/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - _masked_accuracy: 0.9756 - loss: 0.0866\n",
      "Epoch 10: val_loss improved from 0.46549 to 0.46072, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 167ms/step - _masked_accuracy: 0.9761 - loss: 0.0854 - val__masked_accuracy: 0.8884 - val_loss: 0.4607\n",
      "Epoch 11/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - _masked_accuracy: 0.9771 - loss: 0.0807\n",
      "Epoch 11: val_loss did not improve from 0.46072\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 166ms/step - _masked_accuracy: 0.9779 - loss: 0.0785 - val__masked_accuracy: 0.8806 - val_loss: 0.4866\n",
      "Epoch 12/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - _masked_accuracy: 0.9791 - loss: 0.0738\n",
      "Epoch 12: val_loss improved from 0.46072 to 0.45979, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 167ms/step - _masked_accuracy: 0.9794 - loss: 0.0729 - val__masked_accuracy: 0.8868 - val_loss: 0.4598\n",
      "Epoch 13/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - _masked_accuracy: 0.9807 - loss: 0.0682\n",
      "Epoch 13: val_loss improved from 0.45979 to 0.43996, saving model to saved_models_experiment/LSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 169ms/step - _masked_accuracy: 0.9808 - loss: 0.0675 - val__masked_accuracy: 0.8904 - val_loss: 0.4400\n",
      "Epoch 14/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - _masked_accuracy: 0.9811 - loss: 0.0659\n",
      "Epoch 14: val_loss did not improve from 0.43996\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - _masked_accuracy: 0.9814 - loss: 0.0651 - val__masked_accuracy: 0.8809 - val_loss: 0.5130\n",
      "Epoch 15/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - _masked_accuracy: 0.9815 - loss: 0.0631\n",
      "Epoch 15: val_loss did not improve from 0.43996\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - _masked_accuracy: 0.9819 - loss: 0.0625 - val__masked_accuracy: 0.8747 - val_loss: 0.5498\n",
      "Epoch 16/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - _masked_accuracy: 0.9830 - loss: 0.0585\n",
      "Epoch 16: val_loss did not improve from 0.43996\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 167ms/step - _masked_accuracy: 0.9836 - loss: 0.0579 - val__masked_accuracy: 0.8811 - val_loss: 0.5165\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8833\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.69      0.78      1249\n",
      "         ADP       0.96      0.96      0.96      1603\n",
      "         ADV       0.93      0.89      0.91      1058\n",
      "         AUX       0.89      0.91      0.90       691\n",
      "       CCONJ       0.96      0.94      0.95       460\n",
      "         DET       0.96      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.90      0.83      0.86      3111\n",
      "         NUM       0.97      0.90      0.93       233\n",
      "        PART       0.81      0.89      0.85       210\n",
      "        PRON       0.95      0.90      0.93       705\n",
      "       PROPN       0.47      0.90      0.62      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.90      0.79      0.84       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "         UNK       0.00      0.00      0.00         0\n",
      "        VERB       0.91      0.72      0.81      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88     16499\n",
      "   macro avg       0.66      0.65      0.65     16499\n",
      "weighted avg       0.91      0.88      0.89     16499\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_80_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_24             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_36 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_24             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,569,171</span> (9.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,569,171\u001b[0m (9.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,569,171</span> (9.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,569,171\u001b[0m (9.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - _masked_accuracy: 0.4100 - loss: 2.1781\n",
      "Epoch 1: val_loss improved from None to 0.70499, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - _masked_accuracy: 0.5899 - loss: 1.5128 - val__masked_accuracy: 0.8076 - val_loss: 0.7050\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - _masked_accuracy: 0.8669 - loss: 0.5086\n",
      "Epoch 2: val_loss improved from 0.70499 to 0.44802, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - _masked_accuracy: 0.8895 - loss: 0.4188 - val__masked_accuracy: 0.8658 - val_loss: 0.4480\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - _masked_accuracy: 0.9261 - loss: 0.2648\n",
      "Epoch 3: val_loss improved from 0.44802 to 0.39767, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - _masked_accuracy: 0.9333 - loss: 0.2371 - val__masked_accuracy: 0.8791 - val_loss: 0.3977\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - _masked_accuracy: 0.9435 - loss: 0.1863\n",
      "Epoch 4: val_loss improved from 0.39767 to 0.38200, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - _masked_accuracy: 0.9472 - loss: 0.1732 - val__masked_accuracy: 0.8844 - val_loss: 0.3820\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - _masked_accuracy: 0.9520 - loss: 0.1502\n",
      "Epoch 5: val_loss did not improve from 0.38200\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - _masked_accuracy: 0.9542 - loss: 0.1427 - val__masked_accuracy: 0.8848 - val_loss: 0.3873\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - _masked_accuracy: 0.9567 - loss: 0.1284\n",
      "Epoch 6: val_loss did not improve from 0.38200\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 84ms/step - _masked_accuracy: 0.9584 - loss: 0.1237 - val__masked_accuracy: 0.8852 - val_loss: 0.3901\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - _masked_accuracy: 0.9610 - loss: 0.1148\n",
      "Epoch 7: val_loss did not improve from 0.38200\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - _masked_accuracy: 0.9622 - loss: 0.1113 - val__masked_accuracy: 0.8859 - val_loss: 0.3991\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8897\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.82      0.87      1788\n",
      "         ADP       0.89      0.93      0.91      2029\n",
      "         ADV       0.91      0.84      0.87      1191\n",
      "         AUX       0.95      0.94      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.96      0.97      0.97      1897\n",
      "        INTJ       0.96      0.67      0.79       121\n",
      "        NOUN       0.75      0.94      0.83      4123\n",
      "         NUM       0.92      0.68      0.78       542\n",
      "        PART       0.87      0.94      0.90       649\n",
      "        PRON       0.96      0.96      0.96      2165\n",
      "       PROPN       0.89      0.57      0.70      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.82      0.59      0.68       384\n",
      "         SYM       0.78      0.80      0.79       109\n",
      "        VERB       0.86      0.91      0.89      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.89     25096\n",
      "   macro avg       0.85      0.80      0.82     25096\n",
      "weighted avg       0.89      0.89      0.89     25096\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_26             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_38 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_26             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,955,795</span> (22.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,955,795\u001b[0m (22.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,955,795</span> (22.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,955,795\u001b[0m (22.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - _masked_accuracy: 0.5013 - loss: 1.8824\n",
      "Epoch 1: val_loss improved from None to 0.48519, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - _masked_accuracy: 0.6711 - loss: 1.2262 - val__masked_accuracy: 0.8778 - val_loss: 0.4852\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - _masked_accuracy: 0.9054 - loss: 0.3887\n",
      "Epoch 2: val_loss improved from 0.48519 to 0.26600, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - _masked_accuracy: 0.9231 - loss: 0.3172 - val__masked_accuracy: 0.9270 - val_loss: 0.2660\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - _masked_accuracy: 0.9530 - loss: 0.1904\n",
      "Epoch 3: val_loss improved from 0.26600 to 0.23768, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - _masked_accuracy: 0.9573 - loss: 0.1706 - val__masked_accuracy: 0.9282 - val_loss: 0.2377\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - _masked_accuracy: 0.9638 - loss: 0.1321\n",
      "Epoch 4: val_loss improved from 0.23768 to 0.23721, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - _masked_accuracy: 0.9656 - loss: 0.1241 - val__masked_accuracy: 0.9274 - val_loss: 0.2372\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - _masked_accuracy: 0.9679 - loss: 0.1087\n",
      "Epoch 5: val_loss did not improve from 0.23721\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - _masked_accuracy: 0.9691 - loss: 0.1035 - val__masked_accuracy: 0.9280 - val_loss: 0.2375\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - _masked_accuracy: 0.9709 - loss: 0.0944\n",
      "Epoch 6: val_loss did not improve from 0.23721\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - _masked_accuracy: 0.9718 - loss: 0.0907 - val__masked_accuracy: 0.9284 - val_loss: 0.2428\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - _masked_accuracy: 0.9726 - loss: 0.0854\n",
      "Epoch 7: val_loss did not improve from 0.23721\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - _masked_accuracy: 0.9736 - loss: 0.0820 - val__masked_accuracy: 0.9269 - val_loss: 0.2526\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9218\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.76      0.88      0.82       665\n",
      "         ADP       0.99      1.00      0.99      1876\n",
      "         ADV       0.97      0.90      0.93       424\n",
      "         AUX       0.85      0.95      0.90       331\n",
      "       CCONJ       0.99      0.89      0.94       395\n",
      "         DET       0.96      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.88      0.94      0.91      2225\n",
      "         NUM       0.98      0.76      0.86       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.90      0.82      0.86       445\n",
      "       PROPN       0.81      0.79      0.80       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.88      0.92      0.90       336\n",
      "         SYM       1.00      0.76      0.86        25\n",
      "        VERB       0.96      0.82      0.89      1167\n",
      "           X       0.24      0.11      0.15        46\n",
      "\n",
      "    accuracy                           0.92     11941\n",
      "   macro avg       0.77      0.74      0.75     11941\n",
      "weighted avg       0.92      0.92      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_28             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_28 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_40 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_28             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,386,771</span> (24.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,386,771\u001b[0m (24.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,386,771</span> (24.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,386,771\u001b[0m (24.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - _masked_accuracy: 0.4265 - loss: 2.0640\n",
      "Epoch 1: val_loss improved from None to 0.71237, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - _masked_accuracy: 0.5865 - loss: 1.4356 - val__masked_accuracy: 0.8023 - val_loss: 0.7124\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - _masked_accuracy: 0.8576 - loss: 0.4994\n",
      "Epoch 2: val_loss improved from 0.71237 to 0.37575, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 84ms/step - _masked_accuracy: 0.8905 - loss: 0.3955 - val__masked_accuracy: 0.8924 - val_loss: 0.3758\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - _masked_accuracy: 0.9495 - loss: 0.2059\n",
      "Epoch 3: val_loss improved from 0.37575 to 0.32675, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - _masked_accuracy: 0.9572 - loss: 0.1764 - val__masked_accuracy: 0.9014 - val_loss: 0.3268\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - _masked_accuracy: 0.9687 - loss: 0.1214\n",
      "Epoch 4: val_loss improved from 0.32675 to 0.32305, saving model to saved_models_experiment/LSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - _masked_accuracy: 0.9704 - loss: 0.1124 - val__masked_accuracy: 0.9003 - val_loss: 0.3231\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.9744 - loss: 0.0919\n",
      "Epoch 5: val_loss did not improve from 0.32305\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 81ms/step - _masked_accuracy: 0.9757 - loss: 0.0868 - val__masked_accuracy: 0.8989 - val_loss: 0.3249\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.9786 - loss: 0.0734\n",
      "Epoch 6: val_loss did not improve from 0.32305\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - _masked_accuracy: 0.9794 - loss: 0.0702 - val__masked_accuracy: 0.9007 - val_loss: 0.3252\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.9815 - loss: 0.0615\n",
      "Epoch 7: val_loss did not improve from 0.32305\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - _masked_accuracy: 0.9824 - loss: 0.0593 - val__masked_accuracy: 0.9024 - val_loss: 0.3273\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8907\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.93      0.68      0.78      1249\n",
      "         ADP       0.94      0.98      0.96      1603\n",
      "         ADV       0.93      0.91      0.92      1058\n",
      "         AUX       0.88      0.95      0.92       691\n",
      "       CCONJ       0.98      0.93      0.95       460\n",
      "         DET       0.97      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.91      0.83      0.87      3111\n",
      "         NUM       0.99      0.88      0.93       233\n",
      "        PART       0.88      0.71      0.79       210\n",
      "        PRON       0.94      0.91      0.93       705\n",
      "       PROPN       0.56      0.84      0.68      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.89      0.72      0.80       168\n",
      "         SYM       1.00      0.25      0.40         4\n",
      "        VERB       0.74      0.84      0.79      1326\n",
      "           X       1.00      0.04      0.08        25\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89     16499\n",
      "   macro avg       0.81      0.69      0.71     16499\n",
      "weighted avg       0.90      0.89      0.89     16499\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_30             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_42 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_43 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_30             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,979</span> (9.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,580,979\u001b[0m (9.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,979</span> (9.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,580,979\u001b[0m (9.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - _masked_accuracy: 0.2063 - loss: 2.5568\n",
      "Epoch 1: val_loss improved from None to 1.50617, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - _masked_accuracy: 0.3050 - loss: 2.2021 - val__masked_accuracy: 0.5366 - val_loss: 1.5062\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.6314 - loss: 1.2626\n",
      "Epoch 2: val_loss improved from 1.50617 to 0.78179, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - _masked_accuracy: 0.6928 - loss: 1.0682 - val__masked_accuracy: 0.7887 - val_loss: 0.7818\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - _masked_accuracy: 0.8433 - loss: 0.6323\n",
      "Epoch 3: val_loss improved from 0.78179 to 0.52778, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - _masked_accuracy: 0.8699 - loss: 0.5434 - val__masked_accuracy: 0.8569 - val_loss: 0.5278\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.9132 - loss: 0.3754\n",
      "Epoch 4: val_loss improved from 0.52778 to 0.47036, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - _masked_accuracy: 0.9194 - loss: 0.3444 - val__masked_accuracy: 0.8658 - val_loss: 0.4704\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - _masked_accuracy: 0.9281 - loss: 0.2888\n",
      "Epoch 5: val_loss improved from 0.47036 to 0.45111, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - _masked_accuracy: 0.9311 - loss: 0.2727 - val__masked_accuracy: 0.8702 - val_loss: 0.4511\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.9350 - loss: 0.2454\n",
      "Epoch 6: val_loss improved from 0.45111 to 0.43942, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - _masked_accuracy: 0.9369 - loss: 0.2344 - val__masked_accuracy: 0.8728 - val_loss: 0.4394\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - _masked_accuracy: 0.9400 - loss: 0.2159\n",
      "Epoch 7: val_loss did not improve from 0.43942\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - _masked_accuracy: 0.9425 - loss: 0.2068 - val__masked_accuracy: 0.8761 - val_loss: 0.4402\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - _masked_accuracy: 0.9460 - loss: 0.1923\n",
      "Epoch 8: val_loss did not improve from 0.43942\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - _masked_accuracy: 0.9474 - loss: 0.1865 - val__masked_accuracy: 0.8773 - val_loss: 0.4431\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - _masked_accuracy: 0.9502 - loss: 0.1753\n",
      "Epoch 9: val_loss did not improve from 0.43942\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - _masked_accuracy: 0.9513 - loss: 0.1707 - val__masked_accuracy: 0.8788 - val_loss: 0.4459\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8746\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.65      0.85      0.74      1788\n",
      "         ADP       0.88      0.92      0.90      2029\n",
      "         ADV       0.91      0.83      0.87      1191\n",
      "         AUX       0.92      0.95      0.94      1543\n",
      "       CCONJ       1.00      0.99      1.00       736\n",
      "         DET       0.96      0.97      0.96      1897\n",
      "        INTJ       1.00      0.06      0.11       121\n",
      "        NOUN       0.83      0.89      0.86      4123\n",
      "         NUM       0.84      0.60      0.70       542\n",
      "        PART       0.80      0.96      0.87       649\n",
      "        PRON       0.96      0.96      0.96      2165\n",
      "       PROPN       0.89      0.56      0.69      2075\n",
      "       PUNCT       0.98      0.99      0.99      3096\n",
      "       SCONJ       0.79      0.58      0.67       384\n",
      "         SYM       0.96      0.39      0.56       109\n",
      "        VERB       0.85      0.89      0.87      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.87     25096\n",
      "   macro avg       0.84      0.73      0.75     25096\n",
      "weighted avg       0.88      0.87      0.87     25096\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_32             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_32 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_46 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_47 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_32             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,967,603</span> (22.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,967,603\u001b[0m (22.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,967,603</span> (22.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,967,603\u001b[0m (22.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - _masked_accuracy: 0.2939 - loss: 2.2853\n",
      "Epoch 1: val_loss improved from None to 0.99502, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 92ms/step - _masked_accuracy: 0.4531 - loss: 1.7642 - val__masked_accuracy: 0.6724 - val_loss: 0.9950\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.7551 - loss: 0.8368\n",
      "Epoch 2: val_loss improved from 0.99502 to 0.42932, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - _masked_accuracy: 0.8227 - loss: 0.6828 - val__masked_accuracy: 0.9079 - val_loss: 0.4293\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - _masked_accuracy: 0.9256 - loss: 0.3630\n",
      "Epoch 3: val_loss improved from 0.42932 to 0.30285, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - _masked_accuracy: 0.9345 - loss: 0.3154 - val__masked_accuracy: 0.9220 - val_loss: 0.3028\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - _masked_accuracy: 0.9492 - loss: 0.2251\n",
      "Epoch 4: val_loss improved from 0.30285 to 0.27037, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - _masked_accuracy: 0.9525 - loss: 0.2099 - val__masked_accuracy: 0.9298 - val_loss: 0.2704\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9581 - loss: 0.1772\n",
      "Epoch 5: val_loss improved from 0.27037 to 0.26095, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - _masked_accuracy: 0.9594 - loss: 0.1703 - val__masked_accuracy: 0.9306 - val_loss: 0.2609\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9617 - loss: 0.1528\n",
      "Epoch 6: val_loss improved from 0.26095 to 0.25869, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - _masked_accuracy: 0.9626 - loss: 0.1495 - val__masked_accuracy: 0.9314 - val_loss: 0.2587\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9645 - loss: 0.1383\n",
      "Epoch 7: val_loss did not improve from 0.25869\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - _masked_accuracy: 0.9648 - loss: 0.1362 - val__masked_accuracy: 0.9313 - val_loss: 0.2592\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - _masked_accuracy: 0.9659 - loss: 0.1284\n",
      "Epoch 8: val_loss did not improve from 0.25869\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - _masked_accuracy: 0.9665 - loss: 0.1266 - val__masked_accuracy: 0.9314 - val_loss: 0.2601\n",
      "Epoch 9/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - _masked_accuracy: 0.9675 - loss: 0.1201\n",
      "Epoch 9: val_loss did not improve from 0.25869\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - _masked_accuracy: 0.9684 - loss: 0.1180 - val__masked_accuracy: 0.9313 - val_loss: 0.2629\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9257\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.85      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.89      0.93       424\n",
      "         AUX       0.84      0.95      0.90       331\n",
      "       CCONJ       0.99      0.88      0.93       395\n",
      "         DET       0.95      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.95      0.91      0.93      2225\n",
      "         NUM       0.99      0.75      0.85       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.94      0.80      0.87       445\n",
      "       PROPN       0.69      0.93      0.79       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.87      0.96      0.91       336\n",
      "         SYM       0.95      0.76      0.84        25\n",
      "        VERB       0.93      0.84      0.88      1167\n",
      "           X       0.36      0.09      0.14        46\n",
      "\n",
      "    accuracy                           0.93     11941\n",
      "   macro avg       0.78      0.74      0.75     11941\n",
      "weighted avg       0.93      0.93      0.93     11941\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_34             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_34 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_50 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_51 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_34             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │           \u001b[38;5;34m627\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,398,579</span> (24.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,398,579\u001b[0m (24.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,398,579</span> (24.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,398,579\u001b[0m (24.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - _masked_accuracy: 0.2746 - loss: 2.3889\n",
      "Epoch 1: val_loss improved from None to 1.30149, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - _masked_accuracy: 0.4121 - loss: 1.9124 - val__masked_accuracy: 0.5701 - val_loss: 1.3015\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.7032 - loss: 0.9664\n",
      "Epoch 2: val_loss improved from 1.30149 to 0.68244, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - _masked_accuracy: 0.7746 - loss: 0.7925 - val__masked_accuracy: 0.8156 - val_loss: 0.6824\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - _masked_accuracy: 0.9051 - loss: 0.4144\n",
      "Epoch 3: val_loss improved from 0.68244 to 0.51964, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - _masked_accuracy: 0.9232 - loss: 0.3531 - val__masked_accuracy: 0.8668 - val_loss: 0.5196\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9506 - loss: 0.2386\n",
      "Epoch 4: val_loss improved from 0.51964 to 0.50401, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - _masked_accuracy: 0.9538 - loss: 0.2205 - val__masked_accuracy: 0.8641 - val_loss: 0.5040\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9604 - loss: 0.1810\n",
      "Epoch 5: val_loss improved from 0.50401 to 0.46569, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - _masked_accuracy: 0.9617 - loss: 0.1726 - val__masked_accuracy: 0.8771 - val_loss: 0.4657\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - _masked_accuracy: 0.9647 - loss: 0.1532\n",
      "Epoch 6: val_loss did not improve from 0.46569\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - _masked_accuracy: 0.9655 - loss: 0.1482 - val__masked_accuracy: 0.8713 - val_loss: 0.4765\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - _masked_accuracy: 0.9675 - loss: 0.1342\n",
      "Epoch 7: val_loss did not improve from 0.46569\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - _masked_accuracy: 0.9681 - loss: 0.1310 - val__masked_accuracy: 0.8711 - val_loss: 0.4926\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - _masked_accuracy: 0.9697 - loss: 0.1196\n",
      "Epoch 8: val_loss did not improve from 0.46569\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - _masked_accuracy: 0.9705 - loss: 0.1170 - val__masked_accuracy: 0.8701 - val_loss: 0.4946\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8665\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.67      0.77      1249\n",
      "         ADP       0.92      0.99      0.95      1603\n",
      "         ADV       0.93      0.88      0.91      1058\n",
      "         AUX       0.88      0.96      0.92       691\n",
      "       CCONJ       0.97      0.93      0.95       460\n",
      "         DET       0.97      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.94      0.74      0.83      3111\n",
      "         NUM       0.89      0.88      0.88       233\n",
      "        PART       0.94      0.64      0.76       210\n",
      "        PRON       0.93      0.91      0.92       705\n",
      "       PROPN       0.41      0.96      0.57      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.94      0.58      0.72       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.94      0.70      0.80      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.87     16499\n",
      "   macro avg       0.74      0.70      0.70     16499\n",
      "weighted avg       0.91      0.87      0.87     16499\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_36\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_36\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_36             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_36 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_54 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_36             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,652,563</span> (10.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,652,563\u001b[0m (10.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,652,563</span> (10.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,652,563\u001b[0m (10.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - _masked_accuracy: 0.4027 - loss: 2.1093\n",
      "Epoch 1: val_loss improved from None to 0.61666, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 121ms/step - _masked_accuracy: 0.5950 - loss: 1.4191 - val__masked_accuracy: 0.8334 - val_loss: 0.6167\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - _masked_accuracy: 0.8773 - loss: 0.4449\n",
      "Epoch 2: val_loss improved from 0.61666 to 0.40101, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 115ms/step - _masked_accuracy: 0.8978 - loss: 0.3704 - val__masked_accuracy: 0.8864 - val_loss: 0.4010\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.9296 - loss: 0.2434\n",
      "Epoch 3: val_loss improved from 0.40101 to 0.36533, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 119ms/step - _masked_accuracy: 0.9367 - loss: 0.2192 - val__masked_accuracy: 0.8956 - val_loss: 0.3653\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - _masked_accuracy: 0.9466 - loss: 0.1748\n",
      "Epoch 4: val_loss improved from 0.36533 to 0.35010, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - _masked_accuracy: 0.9499 - loss: 0.1627 - val__masked_accuracy: 0.9017 - val_loss: 0.3501\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.9545 - loss: 0.1404\n",
      "Epoch 5: val_loss improved from 0.35010 to 0.34824, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 119ms/step - _masked_accuracy: 0.9566 - loss: 0.1334 - val__masked_accuracy: 0.9022 - val_loss: 0.3482\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - _masked_accuracy: 0.9605 - loss: 0.1193\n",
      "Epoch 6: val_loss did not improve from 0.34824\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 119ms/step - _masked_accuracy: 0.9619 - loss: 0.1147 - val__masked_accuracy: 0.9017 - val_loss: 0.3530\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - _masked_accuracy: 0.9649 - loss: 0.1054\n",
      "Epoch 7: val_loss did not improve from 0.34824\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - _masked_accuracy: 0.9660 - loss: 0.1020 - val__masked_accuracy: 0.9016 - val_loss: 0.3578\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - _masked_accuracy: 0.9686 - loss: 0.0935\n",
      "Epoch 8: val_loss did not improve from 0.34824\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - _masked_accuracy: 0.9694 - loss: 0.0912 - val__masked_accuracy: 0.9006 - val_loss: 0.3683\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9011\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.84      0.86      1788\n",
      "         ADP       0.90      0.92      0.91      2029\n",
      "         ADV       0.90      0.85      0.88      1191\n",
      "         AUX       0.94      0.96      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.97      0.97      0.97      1897\n",
      "        INTJ       0.97      0.69      0.80       121\n",
      "        NOUN       0.86      0.89      0.87      4123\n",
      "         NUM       0.94      0.64      0.76       542\n",
      "        PART       0.85      0.96      0.91       649\n",
      "        PRON       0.96      0.97      0.96      2165\n",
      "       PROPN       0.73      0.80      0.76      2075\n",
      "       PUNCT       0.99      0.98      0.99      3096\n",
      "       SCONJ       0.81      0.62      0.71       384\n",
      "         SYM       0.78      0.85      0.81       109\n",
      "        VERB       0.92      0.89      0.90      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.90     25096\n",
      "   macro avg       0.85      0.81      0.83     25096\n",
      "weighted avg       0.90      0.90      0.90     25096\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_38             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_38 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_56 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_38             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,039,187</span> (23.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,039,187\u001b[0m (23.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,039,187</span> (23.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,039,187\u001b[0m (23.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.5068 - loss: 1.7797\n",
      "Epoch 1: val_loss improved from None to 0.40794, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - _masked_accuracy: 0.6827 - loss: 1.1211 - val__masked_accuracy: 0.8881 - val_loss: 0.4079\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - _masked_accuracy: 0.9117 - loss: 0.3322\n",
      "Epoch 2: val_loss improved from 0.40794 to 0.24360, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 120ms/step - _masked_accuracy: 0.9281 - loss: 0.2750 - val__masked_accuracy: 0.9308 - val_loss: 0.2436\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.9551 - loss: 0.1715\n",
      "Epoch 3: val_loss improved from 0.24360 to 0.22402, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 119ms/step - _masked_accuracy: 0.9592 - loss: 0.1545 - val__masked_accuracy: 0.9333 - val_loss: 0.2240\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.9654 - loss: 0.1219\n",
      "Epoch 4: val_loss did not improve from 0.22402\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 119ms/step - _masked_accuracy: 0.9669 - loss: 0.1146 - val__masked_accuracy: 0.9295 - val_loss: 0.2278\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.9692 - loss: 0.1008\n",
      "Epoch 5: val_loss did not improve from 0.22402\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 118ms/step - _masked_accuracy: 0.9704 - loss: 0.0960 - val__masked_accuracy: 0.9293 - val_loss: 0.2336\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.9718 - loss: 0.0872\n",
      "Epoch 6: val_loss did not improve from 0.22402\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 118ms/step - _masked_accuracy: 0.9730 - loss: 0.0834 - val__masked_accuracy: 0.9286 - val_loss: 0.2439\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9247\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.83      0.85      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.90      0.93       424\n",
      "         AUX       0.86      0.95      0.90       331\n",
      "       CCONJ       0.98      0.90      0.94       395\n",
      "         DET       0.96      0.98      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.91      0.93      0.92      2225\n",
      "         NUM       0.99      0.75      0.85       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.89      0.83      0.86       445\n",
      "       PROPN       0.74      0.89      0.81       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.89      0.92      0.90       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.95      0.83      0.89      1167\n",
      "           X       0.20      0.07      0.10        46\n",
      "\n",
      "    accuracy                           0.92     11941\n",
      "   macro avg       0.77      0.74      0.75     11941\n",
      "weighted avg       0.93      0.92      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Embed_128_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_40\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_40\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_40             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_40 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_58 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_40             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,470,163</span> (24.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,470,163\u001b[0m (24.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,470,163</span> (24.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,470,163\u001b[0m (24.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.4298 - loss: 1.9516\n",
      "Epoch 1: val_loss improved from None to 0.60547, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - _masked_accuracy: 0.6027 - loss: 1.3105 - val__masked_accuracy: 0.8349 - val_loss: 0.6055\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.8764 - loss: 0.4245\n",
      "Epoch 2: val_loss improved from 0.60547 to 0.36488, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 118ms/step - _masked_accuracy: 0.9039 - loss: 0.3385 - val__masked_accuracy: 0.8837 - val_loss: 0.3649\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - _masked_accuracy: 0.9538 - loss: 0.1812\n",
      "Epoch 3: val_loss improved from 0.36488 to 0.32560, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 119ms/step - _masked_accuracy: 0.9602 - loss: 0.1561 - val__masked_accuracy: 0.8947 - val_loss: 0.3256\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - _masked_accuracy: 0.9695 - loss: 0.1114\n",
      "Epoch 4: val_loss improved from 0.32560 to 0.31778, saving model to saved_models_experiment/LSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 119ms/step - _masked_accuracy: 0.9713 - loss: 0.1036 - val__masked_accuracy: 0.8992 - val_loss: 0.3178\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - _masked_accuracy: 0.9755 - loss: 0.0835\n",
      "Epoch 5: val_loss did not improve from 0.31778\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 121ms/step - _masked_accuracy: 0.9768 - loss: 0.0791 - val__masked_accuracy: 0.8912 - val_loss: 0.3539\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.9798 - loss: 0.0668\n",
      "Epoch 6: val_loss did not improve from 0.31778\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 117ms/step - _masked_accuracy: 0.9807 - loss: 0.0642 - val__masked_accuracy: 0.8903 - val_loss: 0.3783\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.9831 - loss: 0.0548\n",
      "Epoch 7: val_loss did not improve from 0.31778\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 117ms/step - _masked_accuracy: 0.9841 - loss: 0.0528 - val__masked_accuracy: 0.8953 - val_loss: 0.3629\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8905\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.70      0.78      1249\n",
      "         ADP       0.96      0.97      0.96      1603\n",
      "         ADV       0.93      0.90      0.92      1058\n",
      "         AUX       0.89      0.96      0.92       691\n",
      "       CCONJ       0.98      0.93      0.95       460\n",
      "         DET       0.97      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.92      0.80      0.86      3111\n",
      "         NUM       0.99      0.88      0.93       233\n",
      "        PART       0.83      0.86      0.84       210\n",
      "        PRON       0.94      0.92      0.93       705\n",
      "       PROPN       0.51      0.90      0.65      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.92      0.73      0.81       168\n",
      "         SYM       1.00      0.50      0.67         4\n",
      "        VERB       0.87      0.82      0.84      1326\n",
      "           X       1.00      0.04      0.08        25\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89     16499\n",
      "   macro avg       0.81      0.72      0.73     16499\n",
      "weighted avg       0.91      0.89      0.89     16499\n",
      "\n",
      "--- Experiment for LSTM_Embed_128_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_42\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_42\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_42             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_42 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_60 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_61 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_42             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,755</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,700,755\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,755</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,700,755\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - _masked_accuracy: 0.2512 - loss: 2.4311\n",
      "Epoch 1: val_loss improved from None to 1.00585, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 160ms/step - _masked_accuracy: 0.4121 - loss: 1.9203 - val__masked_accuracy: 0.7033 - val_loss: 1.0058\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - _masked_accuracy: 0.7863 - loss: 0.7732\n",
      "Epoch 2: val_loss improved from 1.00585 to 0.50274, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - _masked_accuracy: 0.8340 - loss: 0.6178 - val__masked_accuracy: 0.8677 - val_loss: 0.5027\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - _masked_accuracy: 0.9063 - loss: 0.3605\n",
      "Epoch 3: val_loss improved from 0.50274 to 0.41435, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 166ms/step - _masked_accuracy: 0.9155 - loss: 0.3206 - val__masked_accuracy: 0.8825 - val_loss: 0.4143\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - _masked_accuracy: 0.9303 - loss: 0.2537\n",
      "Epoch 4: val_loss improved from 0.41435 to 0.39773, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 166ms/step - _masked_accuracy: 0.9341 - loss: 0.2369 - val__masked_accuracy: 0.8785 - val_loss: 0.3977\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - _masked_accuracy: 0.9377 - loss: 0.2117\n",
      "Epoch 5: val_loss improved from 0.39773 to 0.38741, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - _masked_accuracy: 0.9412 - loss: 0.2009 - val__masked_accuracy: 0.8841 - val_loss: 0.3874\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - _masked_accuracy: 0.9446 - loss: 0.1841\n",
      "Epoch 6: val_loss did not improve from 0.38741\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - _masked_accuracy: 0.9467 - loss: 0.1768 - val__masked_accuracy: 0.8848 - val_loss: 0.3874\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - _masked_accuracy: 0.9484 - loss: 0.1665\n",
      "Epoch 7: val_loss improved from 0.38741 to 0.38377, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - _masked_accuracy: 0.9504 - loss: 0.1604 - val__masked_accuracy: 0.8856 - val_loss: 0.3838\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - _masked_accuracy: 0.9523 - loss: 0.1525\n",
      "Epoch 8: val_loss did not improve from 0.38377\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - _masked_accuracy: 0.9537 - loss: 0.1485 - val__masked_accuracy: 0.8853 - val_loss: 0.4045\n",
      "Epoch 9/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - _masked_accuracy: 0.9550 - loss: 0.1423\n",
      "Epoch 9: val_loss did not improve from 0.38377\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - _masked_accuracy: 0.9560 - loss: 0.1390 - val__masked_accuracy: 0.8850 - val_loss: 0.4024\n",
      "Epoch 10/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - _masked_accuracy: 0.9581 - loss: 0.1336\n",
      "Epoch 10: val_loss did not improve from 0.38377\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 166ms/step - _masked_accuracy: 0.9588 - loss: 0.1302 - val__masked_accuracy: 0.8860 - val_loss: 0.4058\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8870\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.85      0.82      0.84      1788\n",
      "         ADP       0.89      0.92      0.90      2029\n",
      "         ADV       0.89      0.84      0.86      1191\n",
      "         AUX       0.95      0.95      0.95      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.96      0.97      0.97      1897\n",
      "        INTJ       0.82      0.60      0.70       121\n",
      "        NOUN       0.86      0.87      0.87      4123\n",
      "         NUM       0.93      0.63      0.75       542\n",
      "        PART       0.84      0.95      0.89       649\n",
      "        PRON       0.95      0.97      0.96      2165\n",
      "       PROPN       0.79      0.68      0.73      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.83      0.57      0.68       384\n",
      "         SYM       0.79      0.81      0.80       109\n",
      "         UNK       0.00      0.00      0.00         0\n",
      "        VERB       0.77      0.92      0.84      2606\n",
      "           X       0.35      0.14      0.20        42\n",
      "       [UNK]       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89     25096\n",
      "   macro avg       0.76      0.72      0.73     25096\n",
      "weighted avg       0.89      0.89      0.89     25096\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_44\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_44\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_44             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_44 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_64 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_65 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_44             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,087,379</span> (23.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,087,379\u001b[0m (23.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,087,379</span> (23.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,087,379\u001b[0m (23.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - _masked_accuracy: 0.3528 - loss: 2.0932\n",
      "Epoch 1: val_loss improved from None to 0.65992, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 174ms/step - _masked_accuracy: 0.5449 - loss: 1.4860 - val__masked_accuracy: 0.8159 - val_loss: 0.6599\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - _masked_accuracy: 0.8547 - loss: 0.5482\n",
      "Epoch 2: val_loss improved from 0.65992 to 0.31384, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 181ms/step - _masked_accuracy: 0.8882 - loss: 0.4412 - val__masked_accuracy: 0.9211 - val_loss: 0.3138\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - _masked_accuracy: 0.9396 - loss: 0.2512\n",
      "Epoch 3: val_loss improved from 0.31384 to 0.27421, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 181ms/step - _masked_accuracy: 0.9452 - loss: 0.2256 - val__masked_accuracy: 0.9270 - val_loss: 0.2742\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - _masked_accuracy: 0.9561 - loss: 0.1735\n",
      "Epoch 4: val_loss improved from 0.27421 to 0.25677, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 180ms/step - _masked_accuracy: 0.9579 - loss: 0.1645 - val__masked_accuracy: 0.9305 - val_loss: 0.2568\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - _masked_accuracy: 0.9618 - loss: 0.1436\n",
      "Epoch 5: val_loss improved from 0.25677 to 0.25323, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 183ms/step - _masked_accuracy: 0.9628 - loss: 0.1393 - val__masked_accuracy: 0.9316 - val_loss: 0.2532\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - _masked_accuracy: 0.9647 - loss: 0.1283\n",
      "Epoch 6: val_loss did not improve from 0.25323\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 180ms/step - _masked_accuracy: 0.9655 - loss: 0.1250 - val__masked_accuracy: 0.9318 - val_loss: 0.2554\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - _masked_accuracy: 0.9667 - loss: 0.1173\n",
      "Epoch 7: val_loss did not improve from 0.25323\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 178ms/step - _masked_accuracy: 0.9674 - loss: 0.1153 - val__masked_accuracy: 0.9331 - val_loss: 0.2572\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - _masked_accuracy: 0.9683 - loss: 0.1100\n",
      "Epoch 8: val_loss did not improve from 0.25323\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 179ms/step - _masked_accuracy: 0.9688 - loss: 0.1081 - val__masked_accuracy: 0.9321 - val_loss: 0.2603\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9238\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.80      0.87      0.83       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.89      0.93       424\n",
      "         AUX       0.84      0.96      0.90       331\n",
      "       CCONJ       0.99      0.88      0.94       395\n",
      "         DET       0.95      0.99      0.97      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.96      0.91      0.93      2225\n",
      "         NUM       0.98      0.75      0.85       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.90      0.80      0.85       445\n",
      "       PROPN       0.70      0.92      0.80       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.87      0.92      0.89       336\n",
      "         SYM       1.00      0.76      0.86        25\n",
      "        VERB       0.94      0.84      0.88      1167\n",
      "           X       0.38      0.13      0.19        46\n",
      "\n",
      "    accuracy                           0.92     11941\n",
      "   macro avg       0.78      0.74      0.75     11941\n",
      "weighted avg       0.93      0.92      0.92     11941\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='LSTM_Stacked_Embed_128_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_46\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_46\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_46             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_46 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_68 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_69 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_46             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m1,235\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,518,355</span> (24.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,518,355\u001b[0m (24.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,518,355</span> (24.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,518,355\u001b[0m (24.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - _masked_accuracy: 0.2920 - loss: 2.2414\n",
      "Epoch 1: val_loss improved from None to 1.06466, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 172ms/step - _masked_accuracy: 0.4552 - loss: 1.7052 - val__masked_accuracy: 0.6855 - val_loss: 1.0647\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - _masked_accuracy: 0.7520 - loss: 0.8121\n",
      "Epoch 2: val_loss improved from 1.06466 to 0.59254, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 177ms/step - _masked_accuracy: 0.7979 - loss: 0.6740 - val__masked_accuracy: 0.8321 - val_loss: 0.5925\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - _masked_accuracy: 0.9005 - loss: 0.3699\n",
      "Epoch 3: val_loss improved from 0.59254 to 0.53161, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1861s\u001b[0m 9s/step - _masked_accuracy: 0.9173 - loss: 0.3153 - val__masked_accuracy: 0.8497 - val_loss: 0.5316\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - _masked_accuracy: 0.9489 - loss: 0.2063\n",
      "Epoch 4: val_loss improved from 0.53161 to 0.50518, saving model to saved_models_experiment/LSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 168ms/step - _masked_accuracy: 0.9529 - loss: 0.1887 - val__masked_accuracy: 0.8599 - val_loss: 0.5052\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - _masked_accuracy: 0.9596 - loss: 0.1543\n",
      "Epoch 5: val_loss did not improve from 0.50518\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m946s\u001b[0m 4s/step - _masked_accuracy: 0.9612 - loss: 0.1471 - val__masked_accuracy: 0.8592 - val_loss: 0.5288\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - _masked_accuracy: 0.9638 - loss: 0.1319\n",
      "Epoch 6: val_loss did not improve from 0.50518\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 169ms/step - _masked_accuracy: 0.9648 - loss: 0.1276 - val__masked_accuracy: 0.8613 - val_loss: 0.5347\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - _masked_accuracy: 0.9669 - loss: 0.1171\n",
      "Epoch 7: val_loss did not improve from 0.50518\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 168ms/step - _masked_accuracy: 0.9673 - loss: 0.1145 - val__masked_accuracy: 0.8651 - val_loss: 0.5465\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8528\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.93      0.67      0.78      1249\n",
      "         ADP       0.91      0.99      0.95      1603\n",
      "         ADV       0.92      0.90      0.91      1058\n",
      "         AUX       0.88      0.97      0.92       691\n",
      "       CCONJ       0.99      0.93      0.96       460\n",
      "         DET       0.96      0.97      0.97      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.97      0.66      0.79      3111\n",
      "         NUM       0.96      0.88      0.91       233\n",
      "        PART       1.00      0.60      0.75       210\n",
      "        PRON       0.95      0.90      0.93       705\n",
      "       PROPN       0.35      0.96      0.52      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.88      0.62      0.73       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.95      0.70      0.81      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.85     16499\n",
      "   macro avg       0.75      0.69      0.70     16499\n",
      "weighted avg       0.92      0.85      0.87     16499\n",
      "\n",
      "--- Experiment for LSTM_Stacked_Embed_128_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_48\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_48\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_48             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_48 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_48             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,650,771</span> (6.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,650,771\u001b[0m (6.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,650,771</span> (6.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,650,771\u001b[0m (6.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - _masked_accuracy: 0.3924 - loss: 2.1431\n",
      "Epoch 1: val_loss improved from None to 0.60390, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - _masked_accuracy: 0.5846 - loss: 1.4507 - val__masked_accuracy: 0.8276 - val_loss: 0.6039\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - _masked_accuracy: 0.8852 - loss: 0.4177\n",
      "Epoch 2: val_loss improved from 0.60390 to 0.35914, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 86ms/step - _masked_accuracy: 0.9102 - loss: 0.3324 - val__masked_accuracy: 0.8918 - val_loss: 0.3591\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - _masked_accuracy: 0.9497 - loss: 0.1911\n",
      "Epoch 3: val_loss improved from 0.35914 to 0.32645, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - _masked_accuracy: 0.9555 - loss: 0.1679 - val__masked_accuracy: 0.9003 - val_loss: 0.3264\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - _masked_accuracy: 0.9651 - loss: 0.1262\n",
      "Epoch 4: val_loss improved from 0.32645 to 0.31726, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - _masked_accuracy: 0.9679 - loss: 0.1156 - val__masked_accuracy: 0.9049 - val_loss: 0.3173\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - _masked_accuracy: 0.9723 - loss: 0.0965\n",
      "Epoch 5: val_loss improved from 0.31726 to 0.31624, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 113ms/step - _masked_accuracy: 0.9740 - loss: 0.0904 - val__masked_accuracy: 0.9064 - val_loss: 0.3162\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - _masked_accuracy: 0.9774 - loss: 0.0787\n",
      "Epoch 6: val_loss did not improve from 0.31624\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 687ms/step - _masked_accuracy: 0.9785 - loss: 0.0746 - val__masked_accuracy: 0.9071 - val_loss: 0.3179\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - _masked_accuracy: 0.9813 - loss: 0.0663\n",
      "Epoch 7: val_loss did not improve from 0.31624\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - _masked_accuracy: 0.9818 - loss: 0.0630 - val__masked_accuracy: 0.9082 - val_loss: 0.3264\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - _masked_accuracy: 0.9847 - loss: 0.0559\n",
      "Epoch 8: val_loss did not improve from 0.31624\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 115ms/step - _masked_accuracy: 0.9849 - loss: 0.0534 - val__masked_accuracy: 0.9074 - val_loss: 0.3313\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9096\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.82      0.88      0.85      1788\n",
      "         ADP       0.93      0.96      0.95      2029\n",
      "         ADV       0.85      0.89      0.87      1191\n",
      "         AUX       0.98      0.98      0.98      1543\n",
      "       CCONJ       1.00      0.99      0.99       736\n",
      "         DET       0.99      0.99      0.99      1897\n",
      "        INTJ       0.84      0.69      0.76       121\n",
      "        NOUN       0.83      0.91      0.87      4123\n",
      "         NUM       0.87      0.76      0.81       542\n",
      "        PART       0.95      0.97      0.96       649\n",
      "        PRON       0.97      0.99      0.98      2165\n",
      "       PROPN       0.89      0.59      0.71      2075\n",
      "       PUNCT       1.00      0.99      0.99      3096\n",
      "       SCONJ       0.90      0.74      0.81       384\n",
      "         SYM       0.84      0.84      0.84       109\n",
      "        VERB       0.89      0.94      0.91      2606\n",
      "           X       0.18      0.26      0.21        42\n",
      "\n",
      "    accuracy                           0.91     25096\n",
      "   macro avg       0.87      0.85      0.85     25096\n",
      "weighted avg       0.91      0.91      0.91     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_50             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_50 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_50             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,767,411</span> (14.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,767,411\u001b[0m (14.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,767,411</span> (14.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,767,411\u001b[0m (14.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - _masked_accuracy: 0.4611 - loss: 1.8710\n",
      "Epoch 1: val_loss improved from None to 0.41367, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 479ms/step - _masked_accuracy: 0.6535 - loss: 1.1914 - val__masked_accuracy: 0.8860 - val_loss: 0.4137\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - _masked_accuracy: 0.9104 - loss: 0.3321\n",
      "Epoch 2: val_loss improved from 0.41367 to 0.21228, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - _masked_accuracy: 0.9281 - loss: 0.2666 - val__masked_accuracy: 0.9372 - val_loss: 0.2123\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - _masked_accuracy: 0.9584 - loss: 0.1535\n",
      "Epoch 3: val_loss improved from 0.21228 to 0.18497, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - _masked_accuracy: 0.9629 - loss: 0.1369 - val__masked_accuracy: 0.9447 - val_loss: 0.1850\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - _masked_accuracy: 0.9703 - loss: 0.1044\n",
      "Epoch 4: val_loss improved from 0.18497 to 0.17989, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - _masked_accuracy: 0.9723 - loss: 0.0981 - val__masked_accuracy: 0.9461 - val_loss: 0.1799\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - _masked_accuracy: 0.9753 - loss: 0.0833\n",
      "Epoch 5: val_loss improved from 0.17989 to 0.17978, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 112ms/step - _masked_accuracy: 0.9766 - loss: 0.0798 - val__masked_accuracy: 0.9464 - val_loss: 0.1798\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - _masked_accuracy: 0.9784 - loss: 0.0707\n",
      "Epoch 6: val_loss did not improve from 0.17978\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 117ms/step - _masked_accuracy: 0.9793 - loss: 0.0676 - val__masked_accuracy: 0.9455 - val_loss: 0.1819\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - _masked_accuracy: 0.9812 - loss: 0.0605\n",
      "Epoch 7: val_loss did not improve from 0.17978\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 117ms/step - _masked_accuracy: 0.9820 - loss: 0.0582 - val__masked_accuracy: 0.9449 - val_loss: 0.1866\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - _masked_accuracy: 0.9835 - loss: 0.0525\n",
      "Epoch 8: val_loss did not improve from 0.17978\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 118ms/step - _masked_accuracy: 0.9844 - loss: 0.0504 - val__masked_accuracy: 0.9437 - val_loss: 0.1925\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.85      0.86       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.90      0.93       424\n",
      "         AUX       0.94      0.95      0.95       331\n",
      "       CCONJ       0.97      0.91      0.94       395\n",
      "         DET       0.99      0.99      0.99      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.95      0.92      0.93      2225\n",
      "         NUM       0.98      0.87      0.92       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.91      0.94      0.92       445\n",
      "       PROPN       0.73      0.93      0.82       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.89      0.90      0.90       336\n",
      "         SYM       1.00      0.76      0.86        25\n",
      "        VERB       0.95      0.91      0.93      1167\n",
      "           X       0.22      0.13      0.16        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.79      0.76      0.77     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_52\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_52\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_52             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_52 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_52             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,036,771</span> (15.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,036,771\u001b[0m (15.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,036,771</span> (15.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,036,771\u001b[0m (15.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - _masked_accuracy: 0.3911 - loss: 2.0262\n",
      "Epoch 1: val_loss improved from None to 0.60576, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 84ms/step - _masked_accuracy: 0.5792 - loss: 1.3647 - val__masked_accuracy: 0.8187 - val_loss: 0.6058\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - _masked_accuracy: 0.8786 - loss: 0.4087\n",
      "Epoch 2: val_loss improved from 0.60576 to 0.31873, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 4s/step - _masked_accuracy: 0.9084 - loss: 0.3184 - val__masked_accuracy: 0.9004 - val_loss: 0.3187\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - _masked_accuracy: 0.9587 - loss: 0.1583\n",
      "Epoch 3: val_loss improved from 0.31873 to 0.28393, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - _masked_accuracy: 0.9653 - loss: 0.1342 - val__masked_accuracy: 0.9087 - val_loss: 0.2839\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - _masked_accuracy: 0.9749 - loss: 0.0912\n",
      "Epoch 4: val_loss improved from 0.28393 to 0.26130, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - _masked_accuracy: 0.9766 - loss: 0.0847 - val__masked_accuracy: 0.9166 - val_loss: 0.2613\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - _masked_accuracy: 0.9803 - loss: 0.0684\n",
      "Epoch 5: val_loss did not improve from 0.26130\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - _masked_accuracy: 0.9811 - loss: 0.0654 - val__masked_accuracy: 0.9108 - val_loss: 0.2814\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - _masked_accuracy: 0.9841 - loss: 0.0546\n",
      "Epoch 6: val_loss did not improve from 0.26130\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - _masked_accuracy: 0.9846 - loss: 0.0525 - val__masked_accuracy: 0.9048 - val_loss: 0.3100\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - _masked_accuracy: 0.9870 - loss: 0.0446\n",
      "Epoch 7: val_loss did not improve from 0.26130\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 109ms/step - _masked_accuracy: 0.9876 - loss: 0.0428 - val__masked_accuracy: 0.9149 - val_loss: 0.2808\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9114\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.79      0.84      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.93      0.91      0.92      1058\n",
      "         AUX       0.89      0.94      0.91       691\n",
      "       CCONJ       0.98      0.94      0.96       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.94      0.83      0.88      3111\n",
      "         NUM       0.98      0.89      0.93       233\n",
      "        PART       0.99      0.96      0.97       210\n",
      "        PRON       0.98      0.95      0.97       705\n",
      "       PROPN       0.56      0.91      0.69      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.96      0.76      0.85       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.87      0.83      0.85      1326\n",
      "           X       0.50      0.04      0.07        25\n",
      "\n",
      "    accuracy                           0.91     16499\n",
      "   macro avg       0.79      0.75      0.75     16499\n",
      "weighted avg       0.92      0.91      0.91     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_54\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_54\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_54             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_54 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_54             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,749,587</span> (6.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,749,587\u001b[0m (6.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,749,587</span> (6.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,749,587\u001b[0m (6.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - _masked_accuracy: 0.2892 - loss: 2.2951\n",
      "Epoch 1: val_loss improved from None to 0.70893, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 148ms/step - _masked_accuracy: 0.4822 - loss: 1.6825 - val__masked_accuracy: 0.7972 - val_loss: 0.7089\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - _masked_accuracy: 0.8439 - loss: 0.5485\n",
      "Epoch 2: val_loss improved from 0.70893 to 0.43262, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 183ms/step - _masked_accuracy: 0.8756 - loss: 0.4453 - val__masked_accuracy: 0.8785 - val_loss: 0.4326\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - _masked_accuracy: 0.9313 - loss: 0.2556\n",
      "Epoch 3: val_loss improved from 0.43262 to 0.40565, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 189ms/step - _masked_accuracy: 0.9403 - loss: 0.2232 - val__masked_accuracy: 0.8914 - val_loss: 0.4057\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - _masked_accuracy: 0.9558 - loss: 0.1646\n",
      "Epoch 4: val_loss improved from 0.40565 to 0.39526, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - _masked_accuracy: 0.9588 - loss: 0.1520 - val__masked_accuracy: 0.8971 - val_loss: 0.3953\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - _masked_accuracy: 0.9646 - loss: 0.1282\n",
      "Epoch 5: val_loss did not improve from 0.39526\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 207ms/step - _masked_accuracy: 0.9662 - loss: 0.1212 - val__masked_accuracy: 0.8995 - val_loss: 0.4088\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - _masked_accuracy: 0.9691 - loss: 0.1088\n",
      "Epoch 6: val_loss did not improve from 0.39526\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - _masked_accuracy: 0.9708 - loss: 0.1031 - val__masked_accuracy: 0.9015 - val_loss: 0.4106\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - _masked_accuracy: 0.9731 - loss: 0.0942\n",
      "Epoch 7: val_loss did not improve from 0.39526\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 208ms/step - _masked_accuracy: 0.9740 - loss: 0.0902 - val__masked_accuracy: 0.9039 - val_loss: 0.4150\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8997\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.93      0.84      0.88      1788\n",
      "         ADP       0.92      0.97      0.94      2029\n",
      "         ADV       0.92      0.85      0.89      1191\n",
      "         AUX       0.97      0.98      0.97      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.98      0.99      0.98      1897\n",
      "        INTJ       0.99      0.58      0.73       121\n",
      "        NOUN       0.71      0.95      0.81      4123\n",
      "         NUM       0.92      0.61      0.74       542\n",
      "        PART       0.95      0.97      0.96       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.90      0.55      0.68      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.91      0.72      0.80       384\n",
      "         SYM       0.85      0.67      0.75       109\n",
      "         UNK       0.00      0.00      0.00         0\n",
      "        VERB       0.94      0.90      0.92      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.90     25096\n",
      "   macro avg       0.82      0.75      0.78     25096\n",
      "weighted avg       0.91      0.90      0.90     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_56\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_56\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_56             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_56 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_56             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,866,227</span> (14.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,866,227\u001b[0m (14.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,866,227</span> (14.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,866,227\u001b[0m (14.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - _masked_accuracy: 0.3713 - loss: 1.9914\n",
      "Epoch 1: val_loss improved from None to 0.43241, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 171ms/step - _masked_accuracy: 0.5933 - loss: 1.3076 - val__masked_accuracy: 0.8819 - val_loss: 0.4324\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - _masked_accuracy: 0.9028 - loss: 0.3679\n",
      "Epoch 2: val_loss improved from 0.43241 to 0.23150, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 201ms/step - _masked_accuracy: 0.9230 - loss: 0.2947 - val__masked_accuracy: 0.9355 - val_loss: 0.2315\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - _masked_accuracy: 0.9556 - loss: 0.1705\n",
      "Epoch 3: val_loss improved from 0.23150 to 0.22312, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 201ms/step - _masked_accuracy: 0.9595 - loss: 0.1547 - val__masked_accuracy: 0.9370 - val_loss: 0.2231\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - _masked_accuracy: 0.9673 - loss: 0.1227\n",
      "Epoch 4: val_loss improved from 0.22312 to 0.21028, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 202ms/step - _masked_accuracy: 0.9686 - loss: 0.1160 - val__masked_accuracy: 0.9411 - val_loss: 0.2103\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - _masked_accuracy: 0.9712 - loss: 0.1027\n",
      "Epoch 5: val_loss did not improve from 0.21028\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 214ms/step - _masked_accuracy: 0.9720 - loss: 0.0988 - val__masked_accuracy: 0.9398 - val_loss: 0.2157\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - _masked_accuracy: 0.9740 - loss: 0.0900\n",
      "Epoch 6: val_loss did not improve from 0.21028\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 218ms/step - _masked_accuracy: 0.9746 - loss: 0.0875 - val__masked_accuracy: 0.9410 - val_loss: 0.2165\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - _masked_accuracy: 0.9760 - loss: 0.0810\n",
      "Epoch 7: val_loss did not improve from 0.21028\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 221ms/step - _masked_accuracy: 0.9766 - loss: 0.0782 - val__masked_accuracy: 0.9396 - val_loss: 0.2264\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9328\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.82      0.86      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.90      0.94       424\n",
      "         AUX       0.90      0.96      0.93       331\n",
      "       CCONJ       0.99      0.89      0.94       395\n",
      "         DET       0.98      0.98      0.98      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.93      0.93      0.93      2225\n",
      "         NUM       0.96      0.75      0.84       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.92      0.91      0.91       445\n",
      "       PROPN       0.73      0.92      0.81       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.86      0.94      0.90       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.96      0.85      0.90      1167\n",
      "           X       0.25      0.11      0.15        46\n",
      "\n",
      "    accuracy                           0.93     11941\n",
      "   macro avg       0.78      0.75      0.76     11941\n",
      "weighted avg       0.94      0.93      0.93     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_58\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_58\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_58             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_58 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_58             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,135,587</span> (15.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,135,587\u001b[0m (15.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,135,587</span> (15.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,135,587\u001b[0m (15.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - _masked_accuracy: 0.2990 - loss: 2.1783\n",
      "Epoch 1: val_loss improved from None to 0.69446, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - _masked_accuracy: 0.4862 - loss: 1.5761 - val__masked_accuracy: 0.7992 - val_loss: 0.6945\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - _masked_accuracy: 0.8587 - loss: 0.4827\n",
      "Epoch 2: val_loss improved from 0.69446 to 0.38873, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 207ms/step - _masked_accuracy: 0.8944 - loss: 0.3755 - val__masked_accuracy: 0.8897 - val_loss: 0.3887\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - _masked_accuracy: 0.9541 - loss: 0.1828\n",
      "Epoch 3: val_loss improved from 0.38873 to 0.32732, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 205ms/step - _masked_accuracy: 0.9595 - loss: 0.1609 - val__masked_accuracy: 0.9028 - val_loss: 0.3273\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - _masked_accuracy: 0.9679 - loss: 0.1195\n",
      "Epoch 4: val_loss improved from 0.32732 to 0.29437, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 204ms/step - _masked_accuracy: 0.9700 - loss: 0.1115 - val__masked_accuracy: 0.9134 - val_loss: 0.2944\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - _masked_accuracy: 0.9741 - loss: 0.0934\n",
      "Epoch 5: val_loss improved from 0.29437 to 0.29332, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 205ms/step - _masked_accuracy: 0.9751 - loss: 0.0893 - val__masked_accuracy: 0.9131 - val_loss: 0.2933\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - _masked_accuracy: 0.9778 - loss: 0.0779\n",
      "Epoch 6: val_loss did not improve from 0.29332\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 205ms/step - _masked_accuracy: 0.9783 - loss: 0.0756 - val__masked_accuracy: 0.9073 - val_loss: 0.3199\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - _masked_accuracy: 0.9809 - loss: 0.0660\n",
      "Epoch 7: val_loss did not improve from 0.29332\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 200ms/step - _masked_accuracy: 0.9812 - loss: 0.0651 - val__masked_accuracy: 0.9022 - val_loss: 0.3613\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - _masked_accuracy: 0.9834 - loss: 0.0575\n",
      "Epoch 8: val_loss did not improve from 0.29332\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 198ms/step - _masked_accuracy: 0.9835 - loss: 0.0572 - val__masked_accuracy: 0.8982 - val_loss: 0.3989\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9074\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.76      0.83      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.93      0.91      0.92      1058\n",
      "         AUX       0.89      0.98      0.93       691\n",
      "       CCONJ       0.97      0.94      0.95       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.92      0.85      0.88      3111\n",
      "         NUM       1.00      0.88      0.93       233\n",
      "        PART       0.94      0.94      0.94       210\n",
      "        PRON       0.98      0.94      0.96       705\n",
      "       PROPN       0.53      0.91      0.67      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.89      0.81      0.85       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.93      0.77      0.84      1326\n",
      "           X       1.00      0.04      0.08        25\n",
      "\n",
      "    accuracy                           0.91     16499\n",
      "   macro avg       0.81      0.75      0.75     16499\n",
      "weighted avg       0.92      0.91      0.91     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_60\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_60\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_60             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_60 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_60             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792,979</span> (6.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,792,979\u001b[0m (6.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792,979</span> (6.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,792,979\u001b[0m (6.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - _masked_accuracy: 0.3885 - loss: 2.0718\n",
      "Epoch 1: val_loss improved from None to 0.54977, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 164ms/step - _masked_accuracy: 0.5944 - loss: 1.3688 - val__masked_accuracy: 0.8429 - val_loss: 0.5498\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - _masked_accuracy: 0.8932 - loss: 0.3849\n",
      "Epoch 2: val_loss improved from 0.54977 to 0.32250, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 200ms/step - _masked_accuracy: 0.9160 - loss: 0.3064 - val__masked_accuracy: 0.9092 - val_loss: 0.3225\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - _masked_accuracy: 0.9516 - loss: 0.1774\n",
      "Epoch 3: val_loss improved from 0.32250 to 0.30374, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 200ms/step - _masked_accuracy: 0.9572 - loss: 0.1562 - val__masked_accuracy: 0.9113 - val_loss: 0.3037\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - _masked_accuracy: 0.9679 - loss: 0.1151\n",
      "Epoch 4: val_loss improved from 0.30374 to 0.28901, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 204ms/step - _masked_accuracy: 0.9702 - loss: 0.1061 - val__masked_accuracy: 0.9167 - val_loss: 0.2890\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - _masked_accuracy: 0.9741 - loss: 0.0881\n",
      "Epoch 5: val_loss improved from 0.28901 to 0.28814, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 204ms/step - _masked_accuracy: 0.9759 - loss: 0.0824 - val__masked_accuracy: 0.9169 - val_loss: 0.2881\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - _masked_accuracy: 0.9791 - loss: 0.0714\n",
      "Epoch 6: val_loss did not improve from 0.28814\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 204ms/step - _masked_accuracy: 0.9800 - loss: 0.0671 - val__masked_accuracy: 0.9170 - val_loss: 0.2892\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - _masked_accuracy: 0.9823 - loss: 0.0600\n",
      "Epoch 7: val_loss did not improve from 0.28814\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 203ms/step - _masked_accuracy: 0.9833 - loss: 0.0563 - val__masked_accuracy: 0.9182 - val_loss: 0.2955\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - _masked_accuracy: 0.9855 - loss: 0.0500\n",
      "Epoch 8: val_loss did not improve from 0.28814\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 203ms/step - _masked_accuracy: 0.9861 - loss: 0.0473 - val__masked_accuracy: 0.9162 - val_loss: 0.3043\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9194\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.83      0.89      0.86      1788\n",
      "         ADP       0.93      0.97      0.95      2029\n",
      "         ADV       0.89      0.88      0.88      1191\n",
      "         AUX       0.98      0.98      0.98      1543\n",
      "       CCONJ       1.00      0.99      0.99       736\n",
      "         DET       0.99      0.99      0.99      1897\n",
      "        INTJ       0.79      0.68      0.73       121\n",
      "        NOUN       0.87      0.90      0.88      4123\n",
      "         NUM       0.87      0.79      0.83       542\n",
      "        PART       0.95      0.97      0.96       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.80      0.74      0.77      2075\n",
      "       PUNCT       1.00      0.99      0.99      3096\n",
      "       SCONJ       0.90      0.74      0.81       384\n",
      "         SYM       0.79      0.84      0.82       109\n",
      "        VERB       0.92      0.93      0.92      2606\n",
      "           X       0.26      0.21      0.23        42\n",
      "\n",
      "    accuracy                           0.92     25096\n",
      "   macro avg       0.87      0.85      0.86     25096\n",
      "weighted avg       0.92      0.92      0.92     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_62\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_62\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_20                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_62             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_62 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_20                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_62             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,909,619</span> (14.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,909,619\u001b[0m (14.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,909,619</span> (14.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,909,619\u001b[0m (14.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - _masked_accuracy: 0.4742 - loss: 1.7541\n",
      "Epoch 1: val_loss improved from None to 0.34017, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 168ms/step - _masked_accuracy: 0.6779 - loss: 1.0725 - val__masked_accuracy: 0.9016 - val_loss: 0.3402\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - _masked_accuracy: 0.9206 - loss: 0.2802\n",
      "Epoch 2: val_loss improved from 0.34017 to 0.19562, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 205ms/step - _masked_accuracy: 0.9359 - loss: 0.2285 - val__masked_accuracy: 0.9415 - val_loss: 0.1956\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - _masked_accuracy: 0.9615 - loss: 0.1366\n",
      "Epoch 3: val_loss improved from 0.19562 to 0.17564, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 205ms/step - _masked_accuracy: 0.9657 - loss: 0.1215 - val__masked_accuracy: 0.9473 - val_loss: 0.1756\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - _masked_accuracy: 0.9726 - loss: 0.0929\n",
      "Epoch 4: val_loss improved from 0.17564 to 0.17401, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 205ms/step - _masked_accuracy: 0.9743 - loss: 0.0868 - val__masked_accuracy: 0.9464 - val_loss: 0.1740\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - _masked_accuracy: 0.9771 - loss: 0.0744\n",
      "Epoch 5: val_loss did not improve from 0.17401\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 208ms/step - _masked_accuracy: 0.9781 - loss: 0.0709 - val__masked_accuracy: 0.9450 - val_loss: 0.1785\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - _masked_accuracy: 0.9800 - loss: 0.0638\n",
      "Epoch 6: val_loss did not improve from 0.17401\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 206ms/step - _masked_accuracy: 0.9809 - loss: 0.0609 - val__masked_accuracy: 0.9462 - val_loss: 0.1829\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - _masked_accuracy: 0.9825 - loss: 0.0549\n",
      "Epoch 7: val_loss did not improve from 0.17401\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 206ms/step - _masked_accuracy: 0.9833 - loss: 0.0527 - val__masked_accuracy: 0.9449 - val_loss: 0.1886\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9390\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.85      0.86       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.89      0.93       424\n",
      "         AUX       0.94      0.95      0.95       331\n",
      "       CCONJ       0.98      0.91      0.94       395\n",
      "         DET       0.98      0.99      0.99      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.92      0.94      0.93      2225\n",
      "         NUM       0.98      0.84      0.91       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.91      0.92      0.91       445\n",
      "       PROPN       0.79      0.86      0.82       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.88      0.90      0.89       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.93      0.92      0.92      1167\n",
      "           X       0.29      0.13      0.18        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.79      0.76      0.77     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_80_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_64\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_64\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_22                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_64             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_64 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_22                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_64             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,178,979</span> (15.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,178,979\u001b[0m (15.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,178,979</span> (15.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,178,979\u001b[0m (15.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - _masked_accuracy: 0.4111 - loss: 1.9311\n",
      "Epoch 1: val_loss improved from None to 0.51645, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 168ms/step - _masked_accuracy: 0.6028 - loss: 1.2633 - val__masked_accuracy: 0.8431 - val_loss: 0.5164\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - _masked_accuracy: 0.8884 - loss: 0.3614\n",
      "Epoch 2: val_loss improved from 0.51645 to 0.28365, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 205ms/step - _masked_accuracy: 0.9149 - loss: 0.2841 - val__masked_accuracy: 0.9140 - val_loss: 0.2836\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - _masked_accuracy: 0.9611 - loss: 0.1416\n",
      "Epoch 3: val_loss improved from 0.28365 to 0.26640, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 2s/step - _masked_accuracy: 0.9675 - loss: 0.1199 - val__masked_accuracy: 0.9192 - val_loss: 0.2664\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - _masked_accuracy: 0.9768 - loss: 0.0822\n",
      "Epoch 4: val_loss improved from 0.26640 to 0.24345, saving model to saved_models_experiment/BiLSTM_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 220ms/step - _masked_accuracy: 0.9785 - loss: 0.0761 - val__masked_accuracy: 0.9283 - val_loss: 0.2435\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - _masked_accuracy: 0.9824 - loss: 0.0602 \n",
      "Epoch 5: val_loss did not improve from 0.24345\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4256s\u001b[0m 20s/step - _masked_accuracy: 0.9834 - loss: 0.0568 - val__masked_accuracy: 0.9263 - val_loss: 0.2435\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - _masked_accuracy: 0.9864 - loss: 0.0461\n",
      "Epoch 6: val_loss did not improve from 0.24345\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 193ms/step - _masked_accuracy: 0.9871 - loss: 0.0437 - val__masked_accuracy: 0.9218 - val_loss: 0.2682\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - _masked_accuracy: 0.9897 - loss: 0.0356\n",
      "Epoch 7: val_loss did not improve from 0.24345\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 192ms/step - _masked_accuracy: 0.9901 - loss: 0.0343 - val__masked_accuracy: 0.9243 - val_loss: 0.2754\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9238\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.84      0.84      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.92      0.91      0.92      1058\n",
      "         AUX       0.89      0.99      0.93       691\n",
      "       CCONJ       0.98      0.94      0.96       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.92      0.89      0.91      3111\n",
      "         NUM       0.98      0.87      0.92       233\n",
      "        PART       0.95      0.95      0.95       210\n",
      "        PRON       0.97      0.95      0.96       705\n",
      "       PROPN       0.72      0.83      0.77      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.94      0.76      0.84       168\n",
      "         SYM       1.00      0.25      0.40         4\n",
      "        VERB       0.88      0.85      0.87      1326\n",
      "           X       0.11      0.04      0.06        25\n",
      "\n",
      "    accuracy                           0.92     16499\n",
      "   macro avg       0.83      0.77      0.78     16499\n",
      "weighted avg       0.93      0.92      0.92     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_80_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_66\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_66\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_24                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_25                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_66             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_66 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m1,574,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_24                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_25                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_66             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,187,219</span> (8.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,187,219\u001b[0m (8.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,187,219</span> (8.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,187,219\u001b[0m (8.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - _masked_accuracy: 0.3277 - loss: 2.1538\n",
      "Epoch 1: val_loss improved from None to 0.56918, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 328ms/step - _masked_accuracy: 0.5387 - loss: 1.4812 - val__masked_accuracy: 0.8337 - val_loss: 0.5692\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - _masked_accuracy: 0.8829 - loss: 0.4133\n",
      "Epoch 2: val_loss improved from 0.56918 to 0.35710, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 387ms/step - _masked_accuracy: 0.9067 - loss: 0.3319 - val__masked_accuracy: 0.8977 - val_loss: 0.3571\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - _masked_accuracy: 0.9453 - loss: 0.2011\n",
      "Epoch 3: val_loss improved from 0.35710 to 0.33951, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 390ms/step - _masked_accuracy: 0.9510 - loss: 0.1808 - val__masked_accuracy: 0.9043 - val_loss: 0.3395\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - _masked_accuracy: 0.9606 - loss: 0.1440\n",
      "Epoch 4: val_loss improved from 0.33951 to 0.31442, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 393ms/step - _masked_accuracy: 0.9628 - loss: 0.1345 - val__masked_accuracy: 0.9106 - val_loss: 0.3144\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - _masked_accuracy: 0.9674 - loss: 0.1159\n",
      "Epoch 5: val_loss improved from 0.31442 to 0.30546, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 395ms/step - _masked_accuracy: 0.9687 - loss: 0.1105 - val__masked_accuracy: 0.9155 - val_loss: 0.3055\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - _masked_accuracy: 0.9724 - loss: 0.1002\n",
      "Epoch 6: val_loss did not improve from 0.30546\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 389ms/step - _masked_accuracy: 0.9730 - loss: 0.0960 - val__masked_accuracy: 0.9104 - val_loss: 0.3222\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - _masked_accuracy: 0.9754 - loss: 0.0882\n",
      "Epoch 7: val_loss did not improve from 0.30546\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 394ms/step - _masked_accuracy: 0.9759 - loss: 0.0845 - val__masked_accuracy: 0.9120 - val_loss: 0.3297\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - _masked_accuracy: 0.9780 - loss: 0.0770\n",
      "Epoch 8: val_loss did not improve from 0.30546\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 396ms/step - _masked_accuracy: 0.9791 - loss: 0.0738 - val__masked_accuracy: 0.9121 - val_loss: 0.3387\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9143\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.82      0.88      0.85      1788\n",
      "         ADP       0.93      0.97      0.95      2029\n",
      "         ADV       0.90      0.88      0.89      1191\n",
      "         AUX       0.98      0.98      0.98      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.98      0.99      0.99      1897\n",
      "        INTJ       0.97      0.64      0.77       121\n",
      "        NOUN       0.82      0.91      0.86      4123\n",
      "         NUM       0.91      0.72      0.80       542\n",
      "        PART       0.96      0.97      0.96       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.82      0.70      0.76      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.94      0.73      0.82       384\n",
      "         SYM       0.86      0.81      0.83       109\n",
      "        VERB       0.93      0.92      0.92      2606\n",
      "           X       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.91     25096\n",
      "   macro avg       0.87      0.83      0.84     25096\n",
      "weighted avg       0.91      0.91      0.91     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_68\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_68\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,690,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_28                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_29                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_68             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_68 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,690,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_28                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_29                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_68             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,303,859</span> (16.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,303,859\u001b[0m (16.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,303,859</span> (16.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,303,859\u001b[0m (16.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - _masked_accuracy: 0.4198 - loss: 1.8223\n",
      "Epoch 1: val_loss improved from None to 0.33102, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 345ms/step - _masked_accuracy: 0.6459 - loss: 1.1242 - val__masked_accuracy: 0.9065 - val_loss: 0.3310\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - _masked_accuracy: 0.9170 - loss: 0.2945\n",
      "Epoch 2: val_loss improved from 0.33102 to 0.20828, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 439ms/step - _masked_accuracy: 0.9340 - loss: 0.2381 - val__masked_accuracy: 0.9396 - val_loss: 0.2083\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - _masked_accuracy: 0.9598 - loss: 0.1473\n",
      "Epoch 3: val_loss improved from 0.20828 to 0.19567, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 429ms/step - _masked_accuracy: 0.9639 - loss: 0.1328 - val__masked_accuracy: 0.9410 - val_loss: 0.1957\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - _masked_accuracy: 0.9703 - loss: 0.1060\n",
      "Epoch 4: val_loss did not improve from 0.19567\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 436ms/step - _masked_accuracy: 0.9714 - loss: 0.1005 - val__masked_accuracy: 0.9422 - val_loss: 0.1970\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - _masked_accuracy: 0.9736 - loss: 0.0895\n",
      "Epoch 5: val_loss improved from 0.19567 to 0.18666, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 438ms/step - _masked_accuracy: 0.9744 - loss: 0.0861 - val__masked_accuracy: 0.9462 - val_loss: 0.1867\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - _masked_accuracy: 0.9760 - loss: 0.0790\n",
      "Epoch 6: val_loss did not improve from 0.18666\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 434ms/step - _masked_accuracy: 0.9766 - loss: 0.0766 - val__masked_accuracy: 0.9458 - val_loss: 0.1892\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - _masked_accuracy: 0.9775 - loss: 0.0720\n",
      "Epoch 7: val_loss did not improve from 0.18666\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 442ms/step - _masked_accuracy: 0.9782 - loss: 0.0696 - val__masked_accuracy: 0.9456 - val_loss: 0.1966\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - _masked_accuracy: 0.9789 - loss: 0.0661\n",
      "Epoch 8: val_loss did not improve from 0.18666\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 440ms/step - _masked_accuracy: 0.9798 - loss: 0.0637 - val__masked_accuracy: 0.9439 - val_loss: 0.2116\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.85      0.84       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.97      0.89      0.93       424\n",
      "         AUX       0.94      0.96      0.95       331\n",
      "       CCONJ       0.99      0.90      0.94       395\n",
      "         DET       0.98      0.99      0.99      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.95      0.93      0.94      2225\n",
      "         NUM       0.97      0.83      0.90       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.92      0.94      0.93       445\n",
      "       PROPN       0.73      0.92      0.82       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.87      0.93      0.90       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.96      0.89      0.92      1167\n",
      "           X       0.38      0.13      0.19        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.79      0.76      0.77     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_80_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_70\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_70\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_32                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_33                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_70             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_70 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │     \u001b[38;5;34m3,960,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_32                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m214,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_33                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_70             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,573,219</span> (17.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,573,219\u001b[0m (17.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,573,219</span> (17.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,573,219\u001b[0m (17.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - _masked_accuracy: 0.3486 - loss: 2.0041\n",
      "Epoch 1: val_loss improved from None to 0.54656, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - _masked_accuracy: 0.5576 - loss: 1.3394 - val__masked_accuracy: 0.8423 - val_loss: 0.5466\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - _masked_accuracy: 0.8855 - loss: 0.3742\n",
      "Epoch 2: val_loss improved from 0.54656 to 0.42078, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 440ms/step - _masked_accuracy: 0.9132 - loss: 0.2922 - val__masked_accuracy: 0.8847 - val_loss: 0.4208\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - _masked_accuracy: 0.9592 - loss: 0.1491\n",
      "Epoch 3: val_loss improved from 0.42078 to 0.40098, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 437ms/step - _masked_accuracy: 0.9644 - loss: 0.1296 - val__masked_accuracy: 0.8927 - val_loss: 0.4010\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - _masked_accuracy: 0.9723 - loss: 0.0975\n",
      "Epoch 4: val_loss improved from 0.40098 to 0.39887, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 432ms/step - _masked_accuracy: 0.9738 - loss: 0.0915 - val__masked_accuracy: 0.8962 - val_loss: 0.3989\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - _masked_accuracy: 0.9780 - loss: 0.0766\n",
      "Epoch 5: val_loss improved from 0.39887 to 0.37077, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 432ms/step - _masked_accuracy: 0.9784 - loss: 0.0743 - val__masked_accuracy: 0.9074 - val_loss: 0.3708\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - _masked_accuracy: 0.9812 - loss: 0.0630\n",
      "Epoch 6: val_loss improved from 0.37077 to 0.34782, saving model to saved_models_experiment/BiLSTM_Stacked_Embed80_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 438ms/step - _masked_accuracy: 0.9816 - loss: 0.0619 - val__masked_accuracy: 0.9121 - val_loss: 0.3478\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - _masked_accuracy: 0.9844 - loss: 0.0529\n",
      "Epoch 7: val_loss did not improve from 0.34782\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 440ms/step - _masked_accuracy: 0.9844 - loss: 0.0524 - val__masked_accuracy: 0.8961 - val_loss: 0.4505\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - _masked_accuracy: 0.9868 - loss: 0.0457\n",
      "Epoch 8: val_loss did not improve from 0.34782\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 431ms/step - _masked_accuracy: 0.9865 - loss: 0.0455 - val__masked_accuracy: 0.8950 - val_loss: 0.4820\n",
      "Epoch 9/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - _masked_accuracy: 0.9881 - loss: 0.0395\n",
      "Epoch 9: val_loss did not improve from 0.34782\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 430ms/step - _masked_accuracy: 0.9880 - loss: 0.0400 - val__masked_accuracy: 0.8935 - val_loss: 0.5343\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9041\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.70      0.80      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.92      0.90      0.91      1058\n",
      "         AUX       0.89      0.95      0.92       691\n",
      "       CCONJ       0.97      0.94      0.95       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.87      0.89      0.88      3111\n",
      "         NUM       0.94      0.88      0.91       233\n",
      "        PART       0.97      0.92      0.95       210\n",
      "        PRON       0.98      0.95      0.97       705\n",
      "       PROPN       0.56      0.88      0.68      1022\n",
      "       PUNCT       0.99      1.00      1.00      2366\n",
      "       SCONJ       0.95      0.78      0.86       168\n",
      "         SYM       1.00      0.50      0.67         4\n",
      "        VERB       0.93      0.71      0.81      1326\n",
      "           X       0.14      0.04      0.06        25\n",
      "\n",
      "    accuracy                           0.90     16499\n",
      "   macro avg       0.82      0.77      0.78     16499\n",
      "weighted avg       0.92      0.90      0.91     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_80_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_72\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_72\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_36                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_72             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_72 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_36                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_72             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,619,795</span> (9.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,619,795\u001b[0m (9.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,619,795</span> (9.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,619,795\u001b[0m (9.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - _masked_accuracy: 0.4145 - loss: 2.0525\n",
      "Epoch 1: val_loss improved from None to 0.50992, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 105ms/step - _masked_accuracy: 0.6209 - loss: 1.3277 - val__masked_accuracy: 0.8624 - val_loss: 0.5099\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - _masked_accuracy: 0.9065 - loss: 0.3471\n",
      "Epoch 2: val_loss improved from 0.50992 to 0.32780, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 121ms/step - _masked_accuracy: 0.9255 - loss: 0.2786 - val__masked_accuracy: 0.9062 - val_loss: 0.3278\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - _masked_accuracy: 0.9550 - loss: 0.1649\n",
      "Epoch 3: val_loss improved from 0.32780 to 0.29684, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - _masked_accuracy: 0.9606 - loss: 0.1452 - val__masked_accuracy: 0.9143 - val_loss: 0.2968\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - _masked_accuracy: 0.9692 - loss: 0.1103\n",
      "Epoch 4: val_loss improved from 0.29684 to 0.28698, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - _masked_accuracy: 0.9714 - loss: 0.1011 - val__masked_accuracy: 0.9181 - val_loss: 0.2870\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - _masked_accuracy: 0.9761 - loss: 0.0840\n",
      "Epoch 5: val_loss did not improve from 0.28698\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 135ms/step - _masked_accuracy: 0.9775 - loss: 0.0783 - val__masked_accuracy: 0.9174 - val_loss: 0.2878\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - _masked_accuracy: 0.9810 - loss: 0.0672\n",
      "Epoch 6: val_loss did not improve from 0.28698\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - _masked_accuracy: 0.9817 - loss: 0.0631 - val__masked_accuracy: 0.9190 - val_loss: 0.2919\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - _masked_accuracy: 0.9844 - loss: 0.0555\n",
      "Epoch 7: val_loss did not improve from 0.28698\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 147ms/step - _masked_accuracy: 0.9851 - loss: 0.0523 - val__masked_accuracy: 0.9181 - val_loss: 0.2991\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9181\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.88      0.87      1788\n",
      "         ADP       0.93      0.96      0.95      2029\n",
      "         ADV       0.89      0.88      0.89      1191\n",
      "         AUX       0.98      0.99      0.98      1543\n",
      "       CCONJ       1.00      0.99      0.99       736\n",
      "         DET       0.98      0.99      0.99      1897\n",
      "        INTJ       0.98      0.66      0.79       121\n",
      "        NOUN       0.85      0.90      0.88      4123\n",
      "         NUM       0.89      0.75      0.82       542\n",
      "        PART       0.94      0.98      0.96       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.80      0.73      0.76      2075\n",
      "       PUNCT       1.00      0.99      0.99      3096\n",
      "       SCONJ       0.90      0.74      0.81       384\n",
      "         SYM       0.84      0.83      0.84       109\n",
      "        VERB       0.92      0.93      0.92      2606\n",
      "           X       0.16      0.21      0.18        42\n",
      "\n",
      "    accuracy                           0.92     25096\n",
      "   macro avg       0.88      0.85      0.86     25096\n",
      "weighted avg       0.92      0.92      0.92     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_74\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_74\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_38                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_74             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_74 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_38                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_74             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,006,419</span> (22.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,006,419\u001b[0m (22.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,006,419</span> (22.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,006,419\u001b[0m (22.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - _masked_accuracy: 0.5181 - loss: 1.7410\n",
      "Epoch 1: val_loss improved from None to 0.32807, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - _masked_accuracy: 0.6984 - loss: 1.0577 - val__masked_accuracy: 0.9071 - val_loss: 0.3281\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - _masked_accuracy: 0.9286 - loss: 0.2617\n",
      "Epoch 2: val_loss improved from 0.32807 to 0.19310, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 132ms/step - _masked_accuracy: 0.9420 - loss: 0.2126 - val__masked_accuracy: 0.9428 - val_loss: 0.1931\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - _masked_accuracy: 0.9645 - loss: 0.1262\n",
      "Epoch 3: val_loss improved from 0.19310 to 0.17730, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 132ms/step - _masked_accuracy: 0.9678 - loss: 0.1133 - val__masked_accuracy: 0.9469 - val_loss: 0.1773\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - _masked_accuracy: 0.9739 - loss: 0.0877\n",
      "Epoch 4: val_loss improved from 0.17730 to 0.17567, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 135ms/step - _masked_accuracy: 0.9755 - loss: 0.0822 - val__masked_accuracy: 0.9463 - val_loss: 0.1757\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - _masked_accuracy: 0.9783 - loss: 0.0699\n",
      "Epoch 5: val_loss did not improve from 0.17567\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - _masked_accuracy: 0.9795 - loss: 0.0663 - val__masked_accuracy: 0.9459 - val_loss: 0.1794\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - _masked_accuracy: 0.9817 - loss: 0.0587\n",
      "Epoch 6: val_loss did not improve from 0.17567\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 149ms/step - _masked_accuracy: 0.9825 - loss: 0.0560 - val__masked_accuracy: 0.9454 - val_loss: 0.1842\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - _masked_accuracy: 0.9841 - loss: 0.0500\n",
      "Epoch 7: val_loss did not improve from 0.17567\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 152ms/step - _masked_accuracy: 0.9849 - loss: 0.0477 - val__masked_accuracy: 0.9417 - val_loss: 0.1951\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.85      0.86       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.90      0.94       424\n",
      "         AUX       0.94      0.96      0.95       331\n",
      "       CCONJ       0.98      0.90      0.94       395\n",
      "         DET       0.98      0.99      0.98      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.94      0.93      0.93      2225\n",
      "         NUM       0.96      0.86      0.90       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.92      0.92      0.92       445\n",
      "       PROPN       0.77      0.90      0.83       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.88      0.91      0.89       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.94      0.90      0.92      1167\n",
      "           X       0.20      0.17      0.18        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.78      0.76      0.77     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_76\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_76\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_40                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_76             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_76 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_40                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_76             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,437,395</span> (24.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,437,395\u001b[0m (24.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,437,395</span> (24.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,437,395\u001b[0m (24.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - _masked_accuracy: 0.4332 - loss: 1.9253\n",
      "Epoch 1: val_loss improved from None to 0.49990, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - _masked_accuracy: 0.6221 - loss: 1.2483 - val__masked_accuracy: 0.8563 - val_loss: 0.4999\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - _masked_accuracy: 0.9068 - loss: 0.3308\n",
      "Epoch 2: val_loss improved from 0.49990 to 0.28188, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 132ms/step - _masked_accuracy: 0.9300 - loss: 0.2547 - val__masked_accuracy: 0.9155 - val_loss: 0.2819\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - _masked_accuracy: 0.9673 - loss: 0.1243\n",
      "Epoch 3: val_loss improved from 0.28188 to 0.25400, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 132ms/step - _masked_accuracy: 0.9717 - loss: 0.1065 - val__masked_accuracy: 0.9218 - val_loss: 0.2540\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - _masked_accuracy: 0.9789 - loss: 0.0746\n",
      "Epoch 4: val_loss did not improve from 0.25400\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 128ms/step - _masked_accuracy: 0.9801 - loss: 0.0694 - val__masked_accuracy: 0.9224 - val_loss: 0.2567\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - _masked_accuracy: 0.9840 - loss: 0.0556\n",
      "Epoch 5: val_loss did not improve from 0.25400\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 131ms/step - _masked_accuracy: 0.9848 - loss: 0.0526 - val__masked_accuracy: 0.9223 - val_loss: 0.2645\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - _masked_accuracy: 0.9877 - loss: 0.0428\n",
      "Epoch 6: val_loss did not improve from 0.25400\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 139ms/step - _masked_accuracy: 0.9883 - loss: 0.0407 - val__masked_accuracy: 0.9222 - val_loss: 0.2718\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9149\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.82      0.84      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.91      0.91      0.91      1058\n",
      "         AUX       0.89      0.94      0.91       691\n",
      "       CCONJ       0.98      0.94      0.96       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.84      0.93      0.88      3111\n",
      "         NUM       1.00      0.88      0.93       233\n",
      "        PART       0.97      0.94      0.95       210\n",
      "        PRON       0.98      0.94      0.96       705\n",
      "       PROPN       0.73      0.75      0.74      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.93      0.75      0.83       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.93      0.76      0.83      1326\n",
      "           X       1.00      0.04      0.08        25\n",
      "\n",
      "    accuracy                           0.91     16499\n",
      "   macro avg       0.82      0.74      0.75     16499\n",
      "weighted avg       0.92      0.91      0.91     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_64', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_78\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_78\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_42                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_43                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_78             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_78 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_42                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_43                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_78             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,718,611</span> (10.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,718,611\u001b[0m (10.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,718,611</span> (10.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,718,611\u001b[0m (10.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - _masked_accuracy: 0.3174 - loss: 2.2177\n",
      "Epoch 1: val_loss improved from None to 0.57759, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 185ms/step - _masked_accuracy: 0.5258 - loss: 1.5510 - val__masked_accuracy: 0.8395 - val_loss: 0.5776\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - _masked_accuracy: 0.8848 - loss: 0.4235\n",
      "Epoch 2: val_loss improved from 0.57759 to 0.36179, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 225ms/step - _masked_accuracy: 0.9093 - loss: 0.3360 - val__masked_accuracy: 0.8982 - val_loss: 0.3618\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - _masked_accuracy: 0.9483 - loss: 0.1936\n",
      "Epoch 3: val_loss improved from 0.36179 to 0.33711, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 224ms/step - _masked_accuracy: 0.9537 - loss: 0.1714 - val__masked_accuracy: 0.9027 - val_loss: 0.3371\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - _masked_accuracy: 0.9628 - loss: 0.1338\n",
      "Epoch 4: val_loss improved from 0.33711 to 0.33443, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 232ms/step - _masked_accuracy: 0.9650 - loss: 0.1246 - val__masked_accuracy: 0.9053 - val_loss: 0.3344\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - _masked_accuracy: 0.9695 - loss: 0.1077\n",
      "Epoch 5: val_loss improved from 0.33443 to 0.32651, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 235ms/step - _masked_accuracy: 0.9712 - loss: 0.1014 - val__masked_accuracy: 0.9105 - val_loss: 0.3265\n",
      "Epoch 6/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - _masked_accuracy: 0.9737 - loss: 0.0908\n",
      "Epoch 6: val_loss did not improve from 0.32651\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 246ms/step - _masked_accuracy: 0.9749 - loss: 0.0862 - val__masked_accuracy: 0.9095 - val_loss: 0.3329\n",
      "Epoch 7/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - _masked_accuracy: 0.9774 - loss: 0.0785\n",
      "Epoch 7: val_loss did not improve from 0.32651\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 242ms/step - _masked_accuracy: 0.9786 - loss: 0.0743 - val__masked_accuracy: 0.9110 - val_loss: 0.3388\n",
      "Epoch 8/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - _masked_accuracy: 0.9799 - loss: 0.0694\n",
      "Epoch 8: val_loss did not improve from 0.32651\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 243ms/step - _masked_accuracy: 0.9809 - loss: 0.0660 - val__masked_accuracy: 0.9087 - val_loss: 0.3451\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9113\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.88      0.86      1788\n",
      "         ADP       0.93      0.96      0.95      2029\n",
      "         ADV       0.91      0.87      0.89      1191\n",
      "         AUX       0.98      0.98      0.98      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.98      0.99      0.98      1897\n",
      "        INTJ       0.92      0.65      0.76       121\n",
      "        NOUN       0.83      0.91      0.87      4123\n",
      "         NUM       0.64      0.83      0.72       542\n",
      "        PART       0.93      0.97      0.95       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.87      0.61      0.72      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.90      0.75      0.82       384\n",
      "         SYM       0.81      0.86      0.84       109\n",
      "        VERB       0.92      0.93      0.93      2606\n",
      "           X       0.13      0.07      0.09        42\n",
      "\n",
      "    accuracy                           0.91     25096\n",
      "   macro avg       0.86      0.84      0.84     25096\n",
      "weighted avg       0.91      0.91      0.91     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_64 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_64', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_80\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_80\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_46                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_47                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_80             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_80 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_46                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_47                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_80             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,235</span> (23.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,105,235\u001b[0m (23.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,235</span> (23.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,105,235\u001b[0m (23.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - _masked_accuracy: 0.3962 - loss: 1.9250\n",
      "Epoch 1: val_loss improved from None to 0.39191, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 197ms/step - _masked_accuracy: 0.6162 - loss: 1.2427 - val__masked_accuracy: 0.8909 - val_loss: 0.3919\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - _masked_accuracy: 0.9162 - loss: 0.3182\n",
      "Epoch 2: val_loss improved from 0.39191 to 0.22999, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 238ms/step - _masked_accuracy: 0.9346 - loss: 0.2510 - val__masked_accuracy: 0.9307 - val_loss: 0.2300\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - _masked_accuracy: 0.9610 - loss: 0.1443\n",
      "Epoch 3: val_loss improved from 0.22999 to 0.22443, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 241ms/step - _masked_accuracy: 0.9644 - loss: 0.1307 - val__masked_accuracy: 0.9300 - val_loss: 0.2244\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - _masked_accuracy: 0.9695 - loss: 0.1063\n",
      "Epoch 4: val_loss improved from 0.22443 to 0.21890, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 244ms/step - _masked_accuracy: 0.9713 - loss: 0.1007 - val__masked_accuracy: 0.9319 - val_loss: 0.2189\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - _masked_accuracy: 0.9739 - loss: 0.0886\n",
      "Epoch 5: val_loss did not improve from 0.21890\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 240ms/step - _masked_accuracy: 0.9752 - loss: 0.0848 - val__masked_accuracy: 0.9323 - val_loss: 0.2260\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - _masked_accuracy: 0.9770 - loss: 0.0762\n",
      "Epoch 6: val_loss did not improve from 0.21890\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 236ms/step - _masked_accuracy: 0.9779 - loss: 0.0735 - val__masked_accuracy: 0.9317 - val_loss: 0.2368\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - _masked_accuracy: 0.9795 - loss: 0.0676\n",
      "Epoch 7: val_loss did not improve from 0.21890\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 241ms/step - _masked_accuracy: 0.9803 - loss: 0.0652 - val__masked_accuracy: 0.9332 - val_loss: 0.2330\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9306\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.80      0.87      0.83       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.89      0.94       424\n",
      "         AUX       0.93      0.96      0.94       331\n",
      "       CCONJ       0.99      0.88      0.93       395\n",
      "         DET       0.98      0.99      0.99      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.91      0.94      0.92      2225\n",
      "         NUM       0.96      0.81      0.88       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.91      0.93      0.92       445\n",
      "       PROPN       0.85      0.74      0.79       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.88      0.92      0.90       336\n",
      "         SYM       0.95      0.80      0.87        25\n",
      "        VERB       0.91      0.90      0.91      1167\n",
      "           X       0.10      0.20      0.13        46\n",
      "\n",
      "    accuracy                           0.93     11941\n",
      "   macro avg       0.77      0.75      0.76     11941\n",
      "weighted avg       0.93      0.93      0.93     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_64 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_64', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_82\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_82\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_50                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_51                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_82             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_82 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_50                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_51                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_82             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m2,451\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,536,211</span> (24.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,536,211\u001b[0m (24.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,536,211</span> (24.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,536,211\u001b[0m (24.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - _masked_accuracy: 0.3349 - loss: 2.0945\n",
      "Epoch 1: val_loss improved from None to 0.59318, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 197ms/step - _masked_accuracy: 0.5347 - loss: 1.4531 - val__masked_accuracy: 0.8238 - val_loss: 0.5932\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - _masked_accuracy: 0.8811 - loss: 0.4069\n",
      "Epoch 2: val_loss improved from 0.59318 to 0.35148, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 234ms/step - _masked_accuracy: 0.9131 - loss: 0.3097 - val__masked_accuracy: 0.8961 - val_loss: 0.3515\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - _masked_accuracy: 0.9591 - loss: 0.1569\n",
      "Epoch 3: val_loss improved from 0.35148 to 0.33559, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 235ms/step - _masked_accuracy: 0.9646 - loss: 0.1358 - val__masked_accuracy: 0.9022 - val_loss: 0.3356\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - _masked_accuracy: 0.9726 - loss: 0.1008\n",
      "Epoch 4: val_loss improved from 0.33559 to 0.30786, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM64_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - _masked_accuracy: 0.9744 - loss: 0.0938 - val__masked_accuracy: 0.9137 - val_loss: 0.3079\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - _masked_accuracy: 0.9778 - loss: 0.0782 \n",
      "Epoch 5: val_loss did not improve from 0.30786\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5929s\u001b[0m 28s/step - _masked_accuracy: 0.9788 - loss: 0.0748 - val__masked_accuracy: 0.9037 - val_loss: 0.3534\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - _masked_accuracy: 0.9811 - loss: 0.0660\n",
      "Epoch 6: val_loss did not improve from 0.30786\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 410ms/step - _masked_accuracy: 0.9818 - loss: 0.0634 - val__masked_accuracy: 0.8877 - val_loss: 0.4628\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - _masked_accuracy: 0.9835 - loss: 0.0572\n",
      "Epoch 7: val_loss did not improve from 0.30786\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 576ms/step - _masked_accuracy: 0.9843 - loss: 0.0546 - val__masked_accuracy: 0.9138 - val_loss: 0.3476\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9059\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.74      0.82      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.92      0.91      0.92      1058\n",
      "         AUX       0.89      0.95      0.92       691\n",
      "       CCONJ       0.98      0.93      0.95       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.89      0.87      0.88      3111\n",
      "         NUM       0.96      0.87      0.91       233\n",
      "        PART       0.97      0.95      0.96       210\n",
      "        PRON       0.98      0.95      0.97       705\n",
      "       PROPN       0.55      0.90      0.68      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.90      0.78      0.83       168\n",
      "         SYM       0.00      0.00      0.00         4\n",
      "        VERB       0.93      0.74      0.83      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.91     16499\n",
      "   macro avg       0.75      0.74      0.74     16499\n",
      "weighted avg       0.92      0.91      0.91     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_64 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_84\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_84\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_54                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_84             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_84 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_54                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_84             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,786,579</span> (10.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,786,579\u001b[0m (10.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,786,579</span> (10.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,786,579\u001b[0m (10.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - _masked_accuracy: 0.4234 - loss: 1.9647\n",
      "Epoch 1: val_loss improved from None to 0.47160, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 179ms/step - _masked_accuracy: 0.6385 - loss: 1.2254 - val__masked_accuracy: 0.8592 - val_loss: 0.4716\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - _masked_accuracy: 0.9154 - loss: 0.3051\n",
      "Epoch 2: val_loss improved from 0.47160 to 0.32571, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 207ms/step - _masked_accuracy: 0.9322 - loss: 0.2468 - val__masked_accuracy: 0.8973 - val_loss: 0.3257\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - _masked_accuracy: 0.9592 - loss: 0.1481\n",
      "Epoch 3: val_loss did not improve from 0.32571\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - _masked_accuracy: 0.9634 - loss: 0.1317 - val__masked_accuracy: 0.9003 - val_loss: 0.3486\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - _masked_accuracy: 0.9708 - loss: 0.1017\n",
      "Epoch 4: val_loss did not improve from 0.32571\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 219ms/step - _masked_accuracy: 0.9731 - loss: 0.0932 - val__masked_accuracy: 0.9042 - val_loss: 0.3441\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - _masked_accuracy: 0.9773 - loss: 0.0777\n",
      "Epoch 5: val_loss did not improve from 0.32571\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 221ms/step - _masked_accuracy: 0.9786 - loss: 0.0724 - val__masked_accuracy: 0.9060 - val_loss: 0.3347\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9022\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.93      0.82      0.87      1788\n",
      "         ADP       0.93      0.96      0.94      2029\n",
      "         ADV       0.91      0.86      0.88      1191\n",
      "         AUX       0.96      0.98      0.97      1543\n",
      "       CCONJ       1.00      0.99      0.99       736\n",
      "         DET       0.98      0.98      0.98      1897\n",
      "        INTJ       0.99      0.55      0.71       121\n",
      "        NOUN       0.74      0.95      0.83      4123\n",
      "         NUM       0.92      0.66      0.77       542\n",
      "        PART       0.94      0.97      0.95       649\n",
      "        PRON       0.98      0.98      0.98      2165\n",
      "       PROPN       0.88      0.58      0.70      2075\n",
      "       PUNCT       0.99      0.99      0.99      3096\n",
      "       SCONJ       0.84      0.73      0.79       384\n",
      "         SYM       0.86      0.76      0.81       109\n",
      "        VERB       0.92      0.92      0.92      2606\n",
      "           X       0.12      0.02      0.04        42\n",
      "\n",
      "    accuracy                           0.90     25096\n",
      "   macro avg       0.87      0.81      0.83     25096\n",
      "weighted avg       0.91      0.90      0.90     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_86\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_86\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_56                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_86             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_86 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_56                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_86             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,173,203</span> (23.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,173,203\u001b[0m (23.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,173,203</span> (23.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,173,203\u001b[0m (23.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - _masked_accuracy: 0.5425 - loss: 1.6394\n",
      "Epoch 1: val_loss improved from None to 0.28233, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 187ms/step - _masked_accuracy: 0.7233 - loss: 0.9599 - val__masked_accuracy: 0.9195 - val_loss: 0.2823\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - _masked_accuracy: 0.9337 - loss: 0.2340\n",
      "Epoch 2: val_loss improved from 0.28233 to 0.18427, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 223ms/step - _masked_accuracy: 0.9462 - loss: 0.1916 - val__masked_accuracy: 0.9456 - val_loss: 0.1843\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - _masked_accuracy: 0.9667 - loss: 0.1163\n",
      "Epoch 3: val_loss improved from 0.18427 to 0.17810, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 225ms/step - _masked_accuracy: 0.9697 - loss: 0.1045 - val__masked_accuracy: 0.9467 - val_loss: 0.1781\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - _masked_accuracy: 0.9751 - loss: 0.0822\n",
      "Epoch 4: val_loss improved from 0.17810 to 0.17529, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 208ms/step - _masked_accuracy: 0.9767 - loss: 0.0764 - val__masked_accuracy: 0.9461 - val_loss: 0.1753\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - _masked_accuracy: 0.9797 - loss: 0.0653\n",
      "Epoch 5: val_loss did not improve from 0.17529\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 222ms/step - _masked_accuracy: 0.9808 - loss: 0.0615 - val__masked_accuracy: 0.9447 - val_loss: 0.1837\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - _masked_accuracy: 0.9831 - loss: 0.0541\n",
      "Epoch 6: val_loss did not improve from 0.17529\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 219ms/step - _masked_accuracy: 0.9841 - loss: 0.0510 - val__masked_accuracy: 0.9463 - val_loss: 0.1889\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - _masked_accuracy: 0.9858 - loss: 0.0454\n",
      "Epoch 7: val_loss did not improve from 0.17529\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 225ms/step - _masked_accuracy: 0.9865 - loss: 0.0432 - val__masked_accuracy: 0.9455 - val_loss: 0.1968\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9405\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.85      0.87       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.90      0.94       424\n",
      "         AUX       0.93      0.95      0.94       331\n",
      "       CCONJ       0.98      0.91      0.95       395\n",
      "         DET       0.98      0.99      0.98      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.92      0.94      0.93      2225\n",
      "         NUM       0.96      0.83      0.89       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.90      0.93      0.92       445\n",
      "       PROPN       0.80      0.86      0.83       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.90      0.90      0.90       336\n",
      "         SYM       1.00      0.80      0.89        25\n",
      "        VERB       0.93      0.92      0.92      1167\n",
      "           X       0.35      0.24      0.29        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.79      0.77      0.78     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Embed_128_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_88\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_88\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_58                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_88             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_88 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_58                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_88             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,604,179</span> (25.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,604,179\u001b[0m (25.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,604,179</span> (25.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,604,179\u001b[0m (25.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - _masked_accuracy: 0.4605 - loss: 1.8332\n",
      "Epoch 1: val_loss improved from None to 0.42989, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 183ms/step - _masked_accuracy: 0.6457 - loss: 1.1499 - val__masked_accuracy: 0.8689 - val_loss: 0.4299\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - _masked_accuracy: 0.9095 - loss: 0.2993\n",
      "Epoch 2: val_loss improved from 0.42989 to 0.27067, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 201ms/step - _masked_accuracy: 0.9326 - loss: 0.2324 - val__masked_accuracy: 0.9183 - val_loss: 0.2707\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - _masked_accuracy: 0.9682 - loss: 0.1158\n",
      "Epoch 3: val_loss improved from 0.27067 to 0.25940, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 208ms/step - _masked_accuracy: 0.9728 - loss: 0.0988 - val__masked_accuracy: 0.9173 - val_loss: 0.2594\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - _masked_accuracy: 0.9795 - loss: 0.0700\n",
      "Epoch 4: val_loss improved from 0.25940 to 0.24602, saving model to saved_models_experiment/BiLSTM_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 224ms/step - _masked_accuracy: 0.9813 - loss: 0.0640 - val__masked_accuracy: 0.9266 - val_loss: 0.2460\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - _masked_accuracy: 0.9851 - loss: 0.0503\n",
      "Epoch 5: val_loss did not improve from 0.24602\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 223ms/step - _masked_accuracy: 0.9861 - loss: 0.0469 - val__masked_accuracy: 0.9256 - val_loss: 0.2540\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - _masked_accuracy: 0.9895 - loss: 0.0367\n",
      "Epoch 6: val_loss did not improve from 0.24602\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 224ms/step - _masked_accuracy: 0.9896 - loss: 0.0357 - val__masked_accuracy: 0.9132 - val_loss: 0.3087\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - _masked_accuracy: 0.9913 - loss: 0.0298\n",
      "Epoch 7: val_loss did not improve from 0.24602\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 221ms/step - _masked_accuracy: 0.9919 - loss: 0.0282 - val__masked_accuracy: 0.9190 - val_loss: 0.2965\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9182\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.79      0.83      1249\n",
      "         ADP       0.98      0.99      0.98      1603\n",
      "         ADV       0.93      0.91      0.92      1058\n",
      "         AUX       0.90      0.98      0.94       691\n",
      "       CCONJ       0.98      0.94      0.96       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.84      0.93      0.88      3111\n",
      "         NUM       0.98      0.87      0.92       233\n",
      "        PART       0.97      0.96      0.96       210\n",
      "        PRON       0.97      0.96      0.96       705\n",
      "       PROPN       0.72      0.77      0.75      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.93      0.80      0.86       168\n",
      "         SYM       1.00      0.50      0.67         4\n",
      "        VERB       0.95      0.77      0.85      1326\n",
      "           X       0.50      0.04      0.07        25\n",
      "\n",
      "    accuracy                           0.92     16499\n",
      "   macro avg       0.85      0.78      0.80     16499\n",
      "weighted avg       0.92      0.92      0.92     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Embed_128_LSTM_128 on german FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_128', Language='english'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 19676\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_90\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_90\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,518,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_60                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_61                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_90             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_90 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,518,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_60                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_61                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_90             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,180,819</span> (12.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,180,819\u001b[0m (12.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,180,819</span> (12.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,180,819\u001b[0m (12.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - _masked_accuracy: 0.3497 - loss: 2.0884\n",
      "Epoch 1: val_loss improved from None to 0.52060, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 346ms/step - _masked_accuracy: 0.5720 - loss: 1.3816 - val__masked_accuracy: 0.8508 - val_loss: 0.5206\n",
      "Epoch 2/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - _masked_accuracy: 0.9000 - loss: 0.3505\n",
      "Epoch 2: val_loss improved from 0.52060 to 0.38722, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_english.keras\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 415ms/step - _masked_accuracy: 0.9215 - loss: 0.2780 - val__masked_accuracy: 0.8909 - val_loss: 0.3872\n",
      "Epoch 3/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - _masked_accuracy: 0.9543 - loss: 0.1647\n",
      "Epoch 3: val_loss did not improve from 0.38722\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 405ms/step - _masked_accuracy: 0.9590 - loss: 0.1458 - val__masked_accuracy: 0.8972 - val_loss: 0.3878\n",
      "Epoch 4/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - _masked_accuracy: 0.9668 - loss: 0.1147\n",
      "Epoch 4: val_loss did not improve from 0.38722\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 417ms/step - _masked_accuracy: 0.9691 - loss: 0.1063 - val__masked_accuracy: 0.9004 - val_loss: 0.4093\n",
      "Epoch 5/20\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - _masked_accuracy: 0.9729 - loss: 0.0914\n",
      "Epoch 5: val_loss did not improve from 0.38722\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 421ms/step - _masked_accuracy: 0.9745 - loss: 0.0859 - val__masked_accuracy: 0.9031 - val_loss: 0.3960\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.8940\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.91      0.83      0.87      1788\n",
      "         ADP       0.91      0.96      0.94      2029\n",
      "         ADV       0.82      0.84      0.83      1191\n",
      "         AUX       0.96      0.98      0.97      1543\n",
      "       CCONJ       0.99      0.99      0.99       736\n",
      "         DET       0.98      0.98      0.98      1897\n",
      "        INTJ       0.86      0.59      0.70       121\n",
      "        NOUN       0.77      0.92      0.84      4123\n",
      "         NUM       0.88      0.70      0.78       542\n",
      "        PART       0.93      0.96      0.95       649\n",
      "        PRON       0.94      0.98      0.96      2165\n",
      "       PROPN       0.90      0.51      0.65      2075\n",
      "       PUNCT       0.98      0.99      0.99      3096\n",
      "       SCONJ       0.85      0.70      0.77       384\n",
      "         SYM       0.75      0.79      0.77       109\n",
      "         UNK       0.00      0.00      0.00         0\n",
      "        VERB       0.86      0.93      0.90      2606\n",
      "           X       0.15      0.12      0.13        42\n",
      "\n",
      "    accuracy                           0.89     25096\n",
      "   macro avg       0.80      0.76      0.78     25096\n",
      "weighted avg       0.90      0.89      0.89     25096\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_128 on english FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_128', Language='spanish'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 46134\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_92\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_92\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,905,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_64                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_65                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_92             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_92 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m5,905,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_64                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_65                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_92             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,567,443</span> (25.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,567,443\u001b[0m (25.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,567,443</span> (25.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,567,443\u001b[0m (25.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - _masked_accuracy: 0.4476 - loss: 1.7426\n",
      "Epoch 1: val_loss improved from None to 0.29239, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 376ms/step - _masked_accuracy: 0.6780 - loss: 1.0332 - val__masked_accuracy: 0.9182 - val_loss: 0.2924\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - _masked_accuracy: 0.9288 - loss: 0.2566\n",
      "Epoch 2: val_loss improved from 0.29239 to 0.21340, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 454ms/step - _masked_accuracy: 0.9435 - loss: 0.2068 - val__masked_accuracy: 0.9379 - val_loss: 0.2134\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - _masked_accuracy: 0.9642 - loss: 0.1302\n",
      "Epoch 3: val_loss improved from 0.21340 to 0.21058, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 451ms/step - _masked_accuracy: 0.9672 - loss: 0.1191 - val__masked_accuracy: 0.9381 - val_loss: 0.2106\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - _masked_accuracy: 0.9717 - loss: 0.0986\n",
      "Epoch 4: val_loss improved from 0.21058 to 0.19034, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_spanish.keras\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 460ms/step - _masked_accuracy: 0.9728 - loss: 0.0942 - val__masked_accuracy: 0.9460 - val_loss: 0.1903\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - _masked_accuracy: 0.9748 - loss: 0.0841\n",
      "Epoch 5: val_loss did not improve from 0.19034\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 460ms/step - _masked_accuracy: 0.9758 - loss: 0.0803 - val__masked_accuracy: 0.9462 - val_loss: 0.1944\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - _masked_accuracy: 0.9771 - loss: 0.0751\n",
      "Epoch 6: val_loss did not improve from 0.19034\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 461ms/step - _masked_accuracy: 0.9780 - loss: 0.0715 - val__masked_accuracy: 0.9448 - val_loss: 0.2049\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - _masked_accuracy: 0.9791 - loss: 0.0668\n",
      "Epoch 7: val_loss did not improve from 0.19034\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 466ms/step - _masked_accuracy: 0.9798 - loss: 0.0639 - val__masked_accuracy: 0.9420 - val_loss: 0.2201\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9379\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.83      0.85       665\n",
      "         ADP       0.99      0.99      0.99      1876\n",
      "         ADV       0.98      0.90      0.94       424\n",
      "         AUX       0.92      0.96      0.94       331\n",
      "       CCONJ       0.98      0.91      0.94       395\n",
      "         DET       0.98      0.99      0.98      1696\n",
      "        INTJ       0.00      0.00      0.00         1\n",
      "        NOUN       0.93      0.94      0.93      2225\n",
      "         NUM       0.96      0.81      0.88       230\n",
      "        PART       0.00      0.00      0.00         1\n",
      "        PRON       0.91      0.92      0.91       445\n",
      "       PROPN       0.74      0.92      0.82       818\n",
      "       PUNCT       1.00      1.00      1.00      1260\n",
      "       SCONJ       0.88      0.92      0.90       336\n",
      "         SYM       0.91      0.80      0.85        25\n",
      "        VERB       0.96      0.88      0.92      1167\n",
      "           X       0.38      0.13      0.19        46\n",
      "\n",
      "    accuracy                           0.94     11941\n",
      "   macro avg       0.79      0.76      0.77     11941\n",
      "weighted avg       0.94      0.94      0.94     11941\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_128 on spanish FINISHED ---\n",
      "\n",
      "============================================================\n",
      "RUNNING EXPERIMENT: Model='BiLSTM_Stacked_Embed_128_LSTM_128', Language='german'\n",
      "============================================================\n",
      "Loading data...\n",
      "Preprocessing data...\n",
      "Vocab Size: 49501\n",
      "Num Tags: 19\n",
      "Initializing model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_94\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_94\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_68                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_69                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_94             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_94 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m6,336,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_68                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_69                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_94             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m4,883\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,998,419</span> (26.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,998,419\u001b[0m (26.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,998,419</span> (26.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,998,419\u001b[0m (26.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - _masked_accuracy: 0.3781 - loss: 1.9259\n",
      "Epoch 1: val_loss improved from None to 0.47385, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 367ms/step - _masked_accuracy: 0.5912 - loss: 1.2467 - val__masked_accuracy: 0.8678 - val_loss: 0.4738\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - _masked_accuracy: 0.9001 - loss: 0.3314\n",
      "Epoch 2: val_loss improved from 0.47385 to 0.30636, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 454ms/step - _masked_accuracy: 0.9259 - loss: 0.2560 - val__masked_accuracy: 0.9099 - val_loss: 0.3064\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - _masked_accuracy: 0.9638 - loss: 0.1342\n",
      "Epoch 3: val_loss improved from 0.30636 to 0.29155, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 437ms/step - _masked_accuracy: 0.9679 - loss: 0.1178 - val__masked_accuracy: 0.9158 - val_loss: 0.2916\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - _masked_accuracy: 0.9745 - loss: 0.0906\n",
      "Epoch 4: val_loss improved from 0.29155 to 0.26989, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 447ms/step - _masked_accuracy: 0.9761 - loss: 0.0844 - val__masked_accuracy: 0.9227 - val_loss: 0.2699\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - _masked_accuracy: 0.9793 - loss: 0.0728\n",
      "Epoch 5: val_loss improved from 0.26989 to 0.26743, saving model to saved_models_experiment/BiLSTM_Stacked_Embed128_LSTM128_german.keras\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 457ms/step - _masked_accuracy: 0.9800 - loss: 0.0689 - val__masked_accuracy: 0.9252 - val_loss: 0.2674\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - _masked_accuracy: 0.9823 - loss: 0.0610\n",
      "Epoch 6: val_loss did not improve from 0.26743\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 460ms/step - _masked_accuracy: 0.9832 - loss: 0.0578 - val__masked_accuracy: 0.9174 - val_loss: 0.2915\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - _masked_accuracy: 0.9858 - loss: 0.0489\n",
      "Epoch 7: val_loss did not improve from 0.26743\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 454ms/step - _masked_accuracy: 0.9865 - loss: 0.0466 - val__masked_accuracy: 0.9216 - val_loss: 0.2880\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - _masked_accuracy: 0.9883 - loss: 0.0410\n",
      "Epoch 8: val_loss did not improve from 0.26743\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 460ms/step - _masked_accuracy: 0.9886 - loss: 0.0395 - val__masked_accuracy: 0.9210 - val_loss: 0.2917\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training completed.\n",
      "Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9161\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.73      0.85      0.79      1249\n",
      "         ADP       0.97      0.99      0.98      1603\n",
      "         ADV       0.91      0.92      0.91      1058\n",
      "         AUX       0.90      0.97      0.93       691\n",
      "       CCONJ       0.98      0.94      0.96       460\n",
      "         DET       0.98      0.98      0.98      2264\n",
      "        INTJ       0.00      0.00      0.00         4\n",
      "        NOUN       0.90      0.90      0.90      3111\n",
      "         NUM       0.97      0.86      0.91       233\n",
      "        PART       0.95      0.97      0.96       210\n",
      "        PRON       0.97      0.96      0.97       705\n",
      "       PROPN       0.76      0.72      0.74      1022\n",
      "       PUNCT       1.00      1.00      1.00      2366\n",
      "       SCONJ       0.93      0.83      0.87       168\n",
      "         SYM       1.00      0.25      0.40         4\n",
      "        VERB       0.91      0.79      0.85      1326\n",
      "           X       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.92     16499\n",
      "   macro avg       0.81      0.76      0.77     16499\n",
      "weighted avg       0.92      0.92      0.92     16499\n",
      "\n",
      "--- Experiment for BiLSTM_Stacked_Embed_128_LSTM_128 on german FINISHED ---\n",
      "\n",
      "\n",
      "ALL EXPERIMENTS COMPLETED.\n",
      "All results saved to saved_models_experiment/all_experiment_results.json\n"
     ]
    }
   ],
   "source": [
    "for config_name, model_config in EXPERIMENT_CONFIGS.items():\n",
    "    \n",
    "    all_results[config_name] = {}\n",
    "    \n",
    "    for language in LANGUAGES:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"RUNNING EXPERIMENT: Model='{config_name}', Language='{language}'\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        all_results[config_name][language] = {}\n",
    "\n",
    "        # 1. Load Data\n",
    "        print(\"Loading data...\")\n",
    "        train_data, dev_data, test_data = load_data(language)\n",
    "        all_results[config_name][language]['n_train_sents'] = len(train_data)\n",
    "        all_results[config_name][language]['n_dev_sents'] = len(dev_data)\n",
    "        all_results[config_name][language]['n_test_sents'] = len(test_data)\n",
    "\n",
    "        # 2. Preprocess Data\n",
    "        # We create a new preprocessor for each language to build language-specific vocabs\n",
    "        print(\"Preprocessing data...\")\n",
    "        preprocessor = DataPreprocessor(preprocessor_config)\n",
    "\n",
    "        X_train, y_train = preprocessor.process_data_to_pad_sequences(\n",
    "            train_data, is_train_dataset=True\n",
    "        )\n",
    "        X_dev, y_dev = preprocessor.process_data_to_pad_sequences(\n",
    "            dev_data, is_train_dataset=False\n",
    "        )\n",
    "        X_test, y_test = preprocessor.process_data_to_pad_sequences(\n",
    "            test_data, is_train_dataset=False\n",
    "        )\n",
    "        \n",
    "        # Save dataset stats for the report\n",
    "        print(f\"Vocab Size: {preprocessor.vocab_size}\")\n",
    "        print(f\"Num Tags: {preprocessor.num_tags}\")\n",
    "        all_results[config_name][language]['vocab_size'] = preprocessor.vocab_size\n",
    "        all_results[config_name][language]['num_tags'] = preprocessor.num_tags\n",
    "\n",
    "        # 3. Initialize Model\n",
    "        print(\"Initializing model...\")\n",
    "        model = LSTMModel(\n",
    "            model_config,\n",
    "            preprocessor.vocab_size,\n",
    "            preprocessor.num_tags,\n",
    "            preprocessor_config.max_sequence_length,\n",
    "        )\n",
    "        \n",
    "        model.build_model()\n",
    "        model.compile_model()\n",
    "        print(model.get_model().summary()) # For trainable param count\n",
    "\n",
    "        # 4. Train Model\n",
    "        print(\"Training model...\")\n",
    "        trainer = Trainer(model_config.training_config, model, preprocessor)\n",
    "        history = trainer.train((X_train, y_train), (X_dev, y_dev), language)\n",
    "        print(\"Training completed.\")\n",
    "        \n",
    "        # 5. Evaluate Model\n",
    "        print(\"Evaluating model on test set...\")\n",
    "        # Note: The trainer auto-restores the best model. We use that for evaluation.\n",
    "        evaluator = Evaluator(model, preprocessor)\n",
    "        test_metrics = evaluator.evaluate(X_test, y_test, \"Test\")\n",
    "        \n",
    "        # Save key results\n",
    "        all_results[config_name][language]['test_accuracy'] = test_metrics['accuracy']\n",
    "        all_results[config_name][language]['test_f1_macro'] = f1_score(test_metrics['y_true'], test_metrics['y_pred'], average='macro')\n",
    "        all_results[config_name][language]['test_f1_weighted'] = f1_score(test_metrics['y_true'], test_metrics['y_pred'], average='weighted')\n",
    "        all_results[config_name][language]['classification_report'] = classification_report(test_metrics['y_true'], test_metrics['y_pred'], zero_division=0, output_dict=True)\n",
    "\n",
    "        # 6. Save Model and Preprocessor for inference\n",
    "        model_name = f\"{config_name}_{language}\"\n",
    "        preprocessor_path = os.path.join(base_training_config.model_dir, f\"{model_name}_preprocessor.pkl\")\n",
    "        \n",
    "        with open(preprocessor_path, 'wb') as f:\n",
    "            pickle.dump(preprocessor, f)\n",
    "        \n",
    "        print(f\"--- Experiment for {config_name} on {language} FINISHED ---\")\n",
    "\n",
    "print(\"\\n\\nALL EXPERIMENTS COMPLETED.\")\n",
    "\n",
    "# Save results to a JSON file for persistence\n",
    "results_path = os.path.join(base_training_config.model_dir, \"all_experiment_results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    # We can't save the classification_report dict easily, let's simplify\n",
    "    # A more robust way would be to flatten it, but this is fine for now.\n",
    "    temp_results = all_results.copy()\n",
    "    for config_name in temp_results:\n",
    "        for language in temp_results[config_name]:\n",
    "            if 'classification_report' in temp_results[config_name][language]:\n",
    "                del temp_results[config_name][language]['classification_report']\n",
    "                \n",
    "    json.dump(temp_results, f, indent=4)\n",
    "\n",
    "print(f\"All results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67579498",
   "metadata": {},
   "source": [
    "## 4. Collate and Display Results\n",
    "\n",
    "This section formats the collected data from the `all_results` dictionary into markdown tables, ready to be copied into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba3d67d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all_experiment_results.json...\n",
      "Plots will be saved to 'seaborn_plots/'\n",
      "Generating Plot 1: Vocabulary Size by Language...\n",
      "Generating Plot 2: Directionality Comparison...\n",
      "Generating Plot 3: Accuracy vs. F1-Macro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81105/1076339606.py:56: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=df_stats, x='language', y='vocab_size', palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set seaborn style for better-looking plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 1. Load and Flatten Data ---\n",
    "print(\"Loading all_experiment_results.json...\")\n",
    "# Ensure the file is in the same directory as this notebook\n",
    "with open('saved_models_experiment/all_experiment_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten the nested JSON into a list of dictionaries\n",
    "flat_data = []\n",
    "for model_name, languages in data.items():\n",
    "    for language, metrics in languages.items():\n",
    "        # Create a new record for each model-language pair\n",
    "        record = {\n",
    "            'model': model_name,\n",
    "            'language': language,\n",
    "            **metrics  # Add all metric key-value pairs\n",
    "        }\n",
    "        flat_data.append(record)\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(flat_data)\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract key hyperparameters from the model name\n",
    "df['Direction'] = df['model'].apply(lambda x: 'BiLSTM' if 'BiLSTM' in x else 'LSTM')\n",
    "df['Embedding Dim'] = df['model'].apply(lambda x: 128 if 'Embed_128' in x else 80).astype(int)\n",
    "df['LSTM Units'] = df['model'].apply(lambda x: 128 if 'LSTM_128' in x else 64).astype(int)\n",
    "df['Stacked'] = df['model'].apply(lambda x: 'Stacked' if 'Stacked' in x else 'Single')\n",
    "\n",
    "\n",
    "# Create a cleaner label for plotting\n",
    "df['Model Label'] = df['model'].str.replace('_', ' ').str.replace('LSTM', ' LSTM')\n",
    "\n",
    "# Directory to save plots\n",
    "plot_dir = \"seaborn_plots\"\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "print(f\"Plots will be saved to '{plot_dir}/'\")\n",
    "\n",
    "# --- 3. Generate Plots ---\n",
    "plot_files = []\n",
    "\n",
    "# Plot 1: Dataset Statistics (Vocabulary Size)\n",
    "print(\"Generating Plot 1: Vocabulary Size by Language...\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "# We only need one entry per language, so we drop duplicates\n",
    "df_stats = df.drop_duplicates(subset='language')\n",
    "sns.barplot(data=df_stats, x='language', y='vocab_size', palette='viridis')\n",
    "plt.title('Vocabulary Size by Language', fontsize=16)\n",
    "plt.ylabel('Vocabulary Count', fontsize=12)\n",
    "plt.xlabel('Language', fontsize=12)\n",
    "plot_path = os.path.join(plot_dir, '1_vocab_size_by_language.png')\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Key Insight - BiLSTM vs. Unidirectional LSTM\n",
    "print(\"Generating Plot 2: Directionality Comparison...\")\n",
    "g = sns.catplot(\n",
    "    data=df, \n",
    "    x='language', \n",
    "    y='test_accuracy', \n",
    "    hue='Direction', \n",
    "    kind='bar', \n",
    "    palette='colorblind',\n",
    "    aspect=1.5,\n",
    "    legend_out=False\n",
    ")\n",
    "g.fig.suptitle('BiLSTM vs. Unidirectional LSTM (Test Accuracy)', fontsize=16, y=1.03)\n",
    "g.set_axis_labels('Language', 'Test Accuracy', fontsize=12)\n",
    "plt.ylim(0.85, 0.95) # Emphasize the difference\n",
    "g.ax.legend(title='Direction', loc='upper right')\n",
    "plot_path = os.path.join(plot_dir, '2_directionality_comparison.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6e63c-2c2e-4cc0-854f-b22915485d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Accuracy vs. F1-Macro\n",
    "# Find the best model overall (highest mean F1-Macro)\n",
    "best_model_name = df.groupby('model')['test_f1_macro'].mean().idxmax()\n",
    "df_best_model = df[df['model'] == best_model_name]\n",
    "\n",
    "# Melt the dataframe to plot multiple metrics\n",
    "df_melted = df_best_model.melt(\n",
    "    id_vars='language', \n",
    "    value_vars=['test_accuracy', 'test_f1_macro'], \n",
    "    var_name='Metric', \n",
    "    value_name='Score'\n",
    ")\n",
    "# Make labels cleaner\n",
    "df_melted['Metric'] = df_melted['Metric'].map({\n",
    "    'test_accuracy': 'Accuracy',\n",
    "    'test_f1_macro': 'F1-Macro'\n",
    "})\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='language', \n",
    "    y='Score', \n",
    "    hue='Metric', \n",
    "    kind='bar', \n",
    "    palette='Pastel1',\n",
    "    aspect=1.5\n",
    ")\n",
    "g.fig.suptitle(f'Accuracy vs. F1-Macro (Best Model: {best_model_name})', fontsize=16, y=1.03)\n",
    "g.set_axis_labels('Language', 'Score', fontsize=12)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plot_path = os.path.join(plot_dir, '3_accuracy_vs_f1_macro.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bc984d6-3be1-4221-88fb-e97ac5365143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots 4: Model Complexity Heatmaps\n",
    "df_eng_bilstm = df[(df['language'] == 'english') & (df['Direction'] == 'BiLSTM') & (df['Stacked'] == 'Single')]\n",
    "pivot_table = df_eng_bilstm.pivot_table(\n",
    "    index='Embedding Dim', \n",
    "    columns='LSTM Units', \n",
    "    values='test_accuracy'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\", linewidths=.5)\n",
    "plt.title('English BiLSTM: Test Accuracy Heatmap', fontsize=16)\n",
    "plt.xlabel('LSTM Hidden Units', fontsize=12)\n",
    "plt.ylabel('Embedding Dimension', fontsize=12)\n",
    "plot_path = os.path.join(plot_dir, '4_english_bilstm_heatmap.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "df_es_bilstm = df[(df['language'] == 'spanish') & (df['Direction'] == 'BiLSTM') & (df['Stacked'] == 'Single')]\n",
    "pivot_table = df_es_bilstm.pivot_table(\n",
    "    index='Embedding Dim', \n",
    "    columns='LSTM Units', \n",
    "    values='test_accuracy'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\", linewidths=.5)\n",
    "plt.title('Spanish BiLSTM: Test Accuracy Heatmap', fontsize=16)\n",
    "plt.xlabel('LSTM Hidden Units', fontsize=12)\n",
    "plt.ylabel('Embedding Dimension', fontsize=12)\n",
    "plot_path = os.path.join(plot_dir, '4_spanish_bilstm_heatmap.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "df_ge_bilstm = df[(df['language'] == 'german') & (df['Direction'] == 'BiLSTM') & (df['Stacked'] == 'Single')]\n",
    "pivot_table = df_ge_bilstm.pivot_table(\n",
    "    index='Embedding Dim', \n",
    "    columns='LSTM Units', \n",
    "    values='test_accuracy'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\", linewidths=.5)\n",
    "plt.title('German BiLSTM: Test Accuracy Heatmap', fontsize=16)\n",
    "plt.xlabel('LSTM Hidden Units', fontsize=12)\n",
    "plt.ylabel('Embedding Dimension', fontsize=12)\n",
    "plot_path = os.path.join(plot_dir, '4_german_bilstm_heatmap.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6f831-d742-41c1-956e-41bc1826991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5: Full Model Comparison (All Models, All Languages)\n",
    "df_sorted = df.sort_values(by='test_accuracy', ascending=False)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(\n",
    "    data=df_sorted, \n",
    "    x='test_accuracy', \n",
    "    y='Model Label', \n",
    "    hue='language', \n",
    "    palette='muted'\n",
    ")\n",
    "plt.title('Overall Model Performance Comparison (Test Accuracy)', fontsize=16)\n",
    "plt.xlabel('Test Accuracy', fontsize=12)\n",
    "plt.ylabel('Model Configuration', fontsize=12)\n",
    "plt.legend(title='Language', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.axvline(x=0.9, color='r', linestyle='--', label='90% Accuracy') # Add a reference line\n",
    "plt.xlim(0.85, 0.95)\n",
    "plot_path = os.path.join(plot_dir, '5_full_model_comparison(acc).png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05805310-272e-40fd-b073-e92fca9c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6: Full Model Comparison (All Models, All Languages)\n",
    "df_sorted = df.sort_values(by='test_f1_macro', ascending=False)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(\n",
    "    data=df_sorted, \n",
    "    x='test_f1_macro', \n",
    "    y='Model Label', \n",
    "    hue='language', \n",
    "    palette='muted'\n",
    ")\n",
    "plt.title('Overall Model Performance Comparison (Macro F1)', fontsize=16)\n",
    "plt.xlabel('Macro F1', fontsize=12)\n",
    "plt.ylabel('Model Configuration', fontsize=12)\n",
    "plt.legend(title='Language', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.xlim(0.7, 0.9)\n",
    "plot_path = os.path.join(plot_dir, '6_full_model_comparison(f1).png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3caa52-b4fc-4126-b142-7c638cf0d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7: Full Model Comparison (All Models, All Languages)\n",
    "df_sorted = df.sort_values(by='test_f1_weighted', ascending=False)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(\n",
    "    data=df_sorted, \n",
    "    x='test_f1_weighted', \n",
    "    y='Model Label', \n",
    "    hue='language', \n",
    "    palette='muted'\n",
    ")\n",
    "plt.title('Overall Model Performance Comparison (Weighted F1)', fontsize=16)\n",
    "plt.xlabel('Weighted F1', fontsize=12)\n",
    "plt.ylabel('Model Configuration', fontsize=12)\n",
    "plt.legend(title='Language', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.xlim(0.8, 0.95)\n",
    "plot_path = os.path.join(plot_dir, '7_full_model_comparison(f1_weighted).png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0171f4a4-8258-4afd-9485-251a0f8fd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=df, \n",
    "    x='language', \n",
    "    y='test_accuracy', \n",
    "    hue='Stacked', \n",
    "    kind='bar', \n",
    "    palette='colorblind',\n",
    "    aspect=1.5,\n",
    "    legend_out=False\n",
    ")\n",
    "g.fig.suptitle('Stacked vs. Single LSTM (Test Accuracy)', fontsize=16, y=1.03)\n",
    "g.set_axis_labels('Language', 'Test Accuracy', fontsize=12)\n",
    "plt.ylim(0.85, 0.95) # Emphasize the difference\n",
    "g.ax.legend(title='Stacked', loc='upper right')\n",
    "plot_path = os.path.join(plot_dir, '8_stacked_comparison.png')\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plot_files.append(plot_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaf98c",
   "metadata": {},
   "source": [
    "## 5. Qualitative Error Analysis\n",
    "\n",
    "Here, we load our best-performing model (e.g., `BiLSTM_Embed_128` for English) and its corresponding preprocessor to run inference on new, custom sentences. This allows us to find specific examples of 'good', 'bad', and 'ugly' predictions for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8111f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: saved_models_experiment/BiLSTM_Embed_128_LSTM_128_english.keras\n",
      "An error occurred: Could not locate class 'method'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'method', 'config': '_masked_accuracy', 'registered_name': 'method'}\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load the Model and Preprocessor ---\n",
    "\n",
    "# Define which saved model we want to test\n",
    "TARGET_CONFIG = \"BiLSTM_Embed_128_LSTM_128\"\n",
    "TARGET_LANGUAGE = \"english\"\n",
    "\n",
    "model_name = f\"{TARGET_CONFIG}_{TARGET_LANGUAGE}\"\n",
    "model_path = os.path.join(base_training_config.model_dir, f\"{model_name}.keras\")\n",
    "preprocessor_path = os.path.join(base_training_config.model_dir, f\"{model_name}_preprocessor.pkl\")\n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "try:\n",
    "    loaded_model = keras.models.load_model(model_path)\n",
    "    \n",
    "    print(f\"Loading preprocessor from: {preprocessor_path}\")\n",
    "    with open(preprocessor_path, 'rb') as f:\n",
    "        loaded_preprocessor = pickle.load(f)\n",
    "        \n",
    "    # 2. Create Predictor Instance\n",
    "    predictor = Predictor(loaded_model, loaded_preprocessor)\n",
    "\n",
    "    print(\"\\n--- Predictor Ready. Running Qualitative Tests. ---\\n\")\n",
    "    \n",
    "    # --- 3. Run Test Cases ---\n",
    "    \n",
    "    test_sentences = {\n",
    "        \"The 'Good' (Simple Case)\": [\n",
    "            \"Today it is cloudy\",\n",
    "            \"The quick brown fox jumps over the lazy dog .\"\n",
    "        ],\n",
    "        \"The 'Bad' (Ambiguity)\": [\n",
    "            \"The leaves are falling .\", # leaves = NOUN\n",
    "            \"He leaves tomorrow .\", # leaves = VERB\n",
    "            \"I bought an apple .\", # apple = NOUN\n",
    "            \"I work at Apple .\" # Apple = PROPN\n",
    "        ],\n",
    "        \"The 'Ugly' (OOV & Typos)\": [\n",
    "            \"I googled this supercalifragilisticexpialidocious wrd .\",\n",
    "            \"This sentance has twoo mispellings .\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for category, sentences in test_sentences.items():\n",
    "        print(f\"\\n--- {category} ---\")\n",
    "        for sentence in sentences:\n",
    "            predicted_tags = predictor.predict_sentence(sentence)\n",
    "            print(f\"  Sentence: {sentence}\")\n",
    "            print(f\"  Tags:     {' '.join(predicted_tags)}\")\n",
    "            # Optional: Print word-tag pairs\n",
    "            # print(f\"  Result:   {list(zip(sentence.split(), predicted_tags))}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {model_path}\")\n",
    "    print(\"Please ensure the main experiment loop (Section 3) has been run successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c467cb0-df0e-4ba1-9f90-cbc11f663ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
